{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set path to CSV and read in CSV\n",
    "csv_path = Path(\"DATA/ETH/ETH_DATA.csv\")\n",
    "eth_df=pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Currency</th>\n",
       "      <th>Date</th>\n",
       "      <th>Closing Price (USD)</th>\n",
       "      <th>24h Open (USD)</th>\n",
       "      <th>24h High (USD)</th>\n",
       "      <th>24h Low (USD)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-08-09</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-09</td>\n",
       "      <td>0.909046</td>\n",
       "      <td>1.749289</td>\n",
       "      <td>1.916540</td>\n",
       "      <td>0.794497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-10</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>0.692321</td>\n",
       "      <td>0.909046</td>\n",
       "      <td>0.909046</td>\n",
       "      <td>0.692321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-11</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-11</td>\n",
       "      <td>0.668067</td>\n",
       "      <td>0.692321</td>\n",
       "      <td>0.692321</td>\n",
       "      <td>0.654331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-12</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-12</td>\n",
       "      <td>0.850151</td>\n",
       "      <td>0.668067</td>\n",
       "      <td>1.148621</td>\n",
       "      <td>0.668067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-13</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-13</td>\n",
       "      <td>1.266023</td>\n",
       "      <td>0.850151</td>\n",
       "      <td>1.266023</td>\n",
       "      <td>0.850151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-14</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-14</td>\n",
       "      <td>1.951460</td>\n",
       "      <td>1.266023</td>\n",
       "      <td>2.073329</td>\n",
       "      <td>1.149458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-15</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-15</td>\n",
       "      <td>1.591219</td>\n",
       "      <td>1.951460</td>\n",
       "      <td>2.225695</td>\n",
       "      <td>1.591219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-16</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-16</td>\n",
       "      <td>1.693707</td>\n",
       "      <td>1.591219</td>\n",
       "      <td>1.768860</td>\n",
       "      <td>1.591219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-17</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-17</td>\n",
       "      <td>1.423244</td>\n",
       "      <td>1.693707</td>\n",
       "      <td>1.693707</td>\n",
       "      <td>1.099489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-18</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-18</td>\n",
       "      <td>1.199595</td>\n",
       "      <td>1.423244</td>\n",
       "      <td>1.469168</td>\n",
       "      <td>1.193790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Currency        Date  Closing Price (USD)  24h Open (USD)  \\\n",
       "Date                                                                   \n",
       "2015-08-09      ETH  2015-08-09             0.909046        1.749289   \n",
       "2015-08-10      ETH  2015-08-10             0.692321        0.909046   \n",
       "2015-08-11      ETH  2015-08-11             0.668067        0.692321   \n",
       "2015-08-12      ETH  2015-08-12             0.850151        0.668067   \n",
       "2015-08-13      ETH  2015-08-13             1.266023        0.850151   \n",
       "2015-08-14      ETH  2015-08-14             1.951460        1.266023   \n",
       "2015-08-15      ETH  2015-08-15             1.591219        1.951460   \n",
       "2015-08-16      ETH  2015-08-16             1.693707        1.591219   \n",
       "2015-08-17      ETH  2015-08-17             1.423244        1.693707   \n",
       "2015-08-18      ETH  2015-08-18             1.199595        1.423244   \n",
       "\n",
       "            24h High (USD)  24h Low (USD)  \n",
       "Date                                       \n",
       "2015-08-09        1.916540       0.794497  \n",
       "2015-08-10        0.909046       0.692321  \n",
       "2015-08-11        0.692321       0.654331  \n",
       "2015-08-12        1.148621       0.668067  \n",
       "2015-08-13        1.266023       0.850151  \n",
       "2015-08-14        2.073329       1.149458  \n",
       "2015-08-15        2.225695       1.591219  \n",
       "2015-08-16        1.768860       1.591219  \n",
       "2015-08-17        1.693707       1.099489  \n",
       "2015-08-18        1.469168       1.193790  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Set index as Date\n",
    "eth_df = eth_df.set_index(pd.to_datetime(eth_df[\"Date\"], infer_datetime_format=True))\n",
    "\n",
    "# Display sample data\n",
    "eth_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for na\n",
    "eth_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Currency</th>\n",
       "      <th>Date</th>\n",
       "      <th>Closing Price (USD)</th>\n",
       "      <th>24h Open (USD)</th>\n",
       "      <th>24h High (USD)</th>\n",
       "      <th>24h Low (USD)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-08-09</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-09</td>\n",
       "      <td>0.909046</td>\n",
       "      <td>1.749289</td>\n",
       "      <td>1.916540</td>\n",
       "      <td>0.794497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-10</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>0.692321</td>\n",
       "      <td>0.909046</td>\n",
       "      <td>0.909046</td>\n",
       "      <td>0.692321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-11</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-11</td>\n",
       "      <td>0.668067</td>\n",
       "      <td>0.692321</td>\n",
       "      <td>0.692321</td>\n",
       "      <td>0.654331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-12</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-12</td>\n",
       "      <td>0.850151</td>\n",
       "      <td>0.668067</td>\n",
       "      <td>1.148621</td>\n",
       "      <td>0.668067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-13</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-13</td>\n",
       "      <td>1.266023</td>\n",
       "      <td>0.850151</td>\n",
       "      <td>1.266023</td>\n",
       "      <td>0.850151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Currency        Date  Closing Price (USD)  24h Open (USD)  \\\n",
       "Date                                                                   \n",
       "2015-08-09      ETH  2015-08-09             0.909046        1.749289   \n",
       "2015-08-10      ETH  2015-08-10             0.692321        0.909046   \n",
       "2015-08-11      ETH  2015-08-11             0.668067        0.692321   \n",
       "2015-08-12      ETH  2015-08-12             0.850151        0.668067   \n",
       "2015-08-13      ETH  2015-08-13             1.266023        0.850151   \n",
       "\n",
       "            24h High (USD)  24h Low (USD)  \n",
       "Date                                       \n",
       "2015-08-09        1.916540       0.794497  \n",
       "2015-08-10        0.909046       0.692321  \n",
       "2015-08-11        0.692321       0.654331  \n",
       "2015-08-12        1.148621       0.668067  \n",
       "2015-08-13        1.266023       0.850151  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check main_df to see if everything is correct \n",
    "eth_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed to (2)\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to amke x and y\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[0.909046 0.692321 0.668067 0.850151 1.266023 1.95146  1.591219 1.693707\n",
      "  1.423244]\n",
      " [0.692321 0.668067 0.850151 1.266023 1.95146  1.591219 1.693707 1.423244\n",
      "  1.199595]\n",
      " [0.668067 0.850151 1.266023 1.95146  1.591219 1.693707 1.423244 1.199595\n",
      "  1.182837]] \n",
      "\n",
      "y sample values:\n",
      "[[1.199595]\n",
      " [1.182837]\n",
      " [1.279549]]\n"
     ]
    }
   ],
   "source": [
    "# Define the window size\n",
    "window_size = 9\n",
    "\n",
    "# Set the index of the feature and target columns\n",
    "feature_column = 2\n",
    "target_column = 2\n",
    "\n",
    "# Create the features (X) and target (y) data using the window_data() function.\n",
    "X, y = window_data(eth_df, window_size, feature_column, target_column)\n",
    "\n",
    "# Print a few sample values from X and y\n",
    "print (f\"X sample values:\\n{X[:3]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Manually splitting the data\n",
    "split = int(0.7 * len(X))\n",
    "\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Importing the MinMaxScaler from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the MinMaxScaler object with the features data X\n",
    "scaler.fit(X)\n",
    "\n",
    "# Scale the features training and testing sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the MinMaxScaler object with the target data Y\n",
    "scaler.fit(y)\n",
    "\n",
    "# Scale the target training and testing sets\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample values:\n",
      "[[[1.16315033e-04]\n",
      "  [6.38688232e-05]\n",
      "  [5.79994940e-05]\n",
      "  [1.02062780e-04]\n",
      "  [2.02701423e-04]\n",
      "  [3.68573253e-04]\n",
      "  [2.81396994e-04]\n",
      "  [3.06198503e-04]\n",
      "  [2.40748005e-04]]\n",
      "\n",
      " [[6.38688232e-05]\n",
      "  [5.79994940e-05]\n",
      "  [1.02062780e-04]\n",
      "  [2.02701423e-04]\n",
      "  [3.68573253e-04]\n",
      "  [2.81396994e-04]\n",
      "  [3.06198503e-04]\n",
      "  [2.40748005e-04]\n",
      "  [1.86626227e-04]]\n",
      "\n",
      " [[5.79994940e-05]\n",
      "  [1.02062780e-04]\n",
      "  [2.02701423e-04]\n",
      "  [3.68573253e-04]\n",
      "  [2.81396994e-04]\n",
      "  [3.06198503e-04]\n",
      "  [2.40748005e-04]\n",
      "  [1.86626227e-04]\n",
      "  [1.82570887e-04]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[0.04090703]\n",
      "  [0.04379478]\n",
      "  [0.04364628]\n",
      "  [0.04663782]\n",
      "  [0.0464072 ]\n",
      "  [0.04369936]\n",
      "  [0.0436468 ]\n",
      "  [0.04382717]\n",
      "  [0.04493723]]\n",
      "\n",
      " [[0.04379478]\n",
      "  [0.04364628]\n",
      "  [0.04663782]\n",
      "  [0.0464072 ]\n",
      "  [0.04369936]\n",
      "  [0.0436468 ]\n",
      "  [0.04382717]\n",
      "  [0.04493723]\n",
      "  [0.04359566]]\n",
      "\n",
      " [[0.04364628]\n",
      "  [0.04663782]\n",
      "  [0.0464072 ]\n",
      "  [0.04369936]\n",
      "  [0.0436468 ]\n",
      "  [0.04382717]\n",
      "  [0.04493723]\n",
      "  [0.04359566]\n",
      "  [0.04218582]]]\n"
     ]
    }
   ],
   "source": [
    " # Reshape the features data\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Print some sample data after reshaping the datasets\n",
    "print (f\"X_train sample values:\\n{X_train[:3]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Importing required Keras modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model.\n",
    "model = Sequential()\n",
    "\n",
    "# Initial model setup\n",
    "number_units = 9\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_54 (LSTM)               (None, 9, 9)              396       \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 9, 9)              0         \n",
      "_________________________________________________________________\n",
      "lstm_55 (LSTM)               (None, 9, 9)              684       \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 9, 9)              0         \n",
      "_________________________________________________________________\n",
      "lstm_56 (LSTM)               (None, 9)                 684       \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 9)                 0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 10        \n",
      "=================================================================\n",
      "Total params: 1,774\n",
      "Trainable params: 1,774\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "17/17 [==============================] - 5s 10ms/step - loss: 0.0034\n",
      "Epoch 2/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0032\n",
      "Epoch 3/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0029\n",
      "Epoch 4/10\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0022\n",
      "Epoch 5/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0018\n",
      "Epoch 6/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 0.0013\n",
      "Epoch 7/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 6.5026e-04\n",
      "Epoch 8/10\n",
      "17/17 [==============================] - 0s 10ms/step - loss: 5.0605e-04\n",
      "Epoch 9/10\n",
      "17/17 [==============================] - 0s 12ms/step - loss: 4.4086e-04: 0s - loss: 5.7382e-\n",
      "Epoch 10/10\n",
      "17/17 [==============================] - 0s 15ms/step - loss: 4.8852e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1aa60bd2a60>"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=90, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002731719985604286"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Evaluate the model\n",
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Make predictions using the testing data X_test\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-10-15</th>\n",
       "      <td>180.580000</td>\n",
       "      <td>197.040695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-16</th>\n",
       "      <td>174.754083</td>\n",
       "      <td>199.505341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-17</th>\n",
       "      <td>176.390105</td>\n",
       "      <td>199.829056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-18</th>\n",
       "      <td>173.750089</td>\n",
       "      <td>200.050232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-19</th>\n",
       "      <td>171.158513</td>\n",
       "      <td>197.904816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Actual   Predicted\n",
       "Date                              \n",
       "2019-10-15  180.580000  197.040695\n",
       "2019-10-16  174.754083  199.505341\n",
       "2019-10-17  176.390105  199.829056\n",
       "2019-10-18  173.750089  200.050232\n",
       "2019-10-19  171.158513  197.904816"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Create a DataFrame of Real and Predicted values\n",
    "eth_eval = pd.DataFrame({\n",
    "    \"Actual\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = eth_df.index[-len(real_prices): ]) \n",
    "\n",
    "# Show the DataFrame's head\n",
    "eth_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Actual Vs. Predicted ETH Prices'}, xlabel='Date'>"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Plot the real vs predicted prices as a line chart\n",
    "eth_eval.plot(title=\"Actual Vs. Predicted ETH Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46647.24108071358\n",
      "215.97972377219483\n",
      "102.59572350824543\n"
     ]
    }
   ],
   "source": [
    "#seprate actual and pred\n",
    "Pred= eth_eval['Actual']\n",
    "act= eth_eval['Predicted']\n",
    "\n",
    "#model eval\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "print(mean_squared_error(act, Pred))\n",
    "print(math.sqrt(mean_squared_error(act, Pred)))\n",
    "print(mean_absolute_error(act, Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign atributes to names\n",
    "#future period desides how many days ahead data will be \n",
    "FUTURE_PERIOD_PREDICT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create buy and sell signals \n",
    "#def classification \n",
    "\n",
    "def classify(predicted, future):\n",
    "    if future > predicted:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set data 3 days back to compensate for lag\n",
    "def add_future_column(eth_df):\n",
    "    main_df= eth_df.copy()\n",
    "    main_df['future'] = eth_df[\"Closing Price (USD)\"].shift(-FUTURE_PERIOD_PREDICT)\n",
    "    \n",
    "    main_df.dropna(inplace=True)\n",
    "\n",
    "    main_df.head()\n",
    "    \n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Currency</th>\n",
       "      <th>Date</th>\n",
       "      <th>Closing Price (USD)</th>\n",
       "      <th>24h Open (USD)</th>\n",
       "      <th>24h High (USD)</th>\n",
       "      <th>24h Low (USD)</th>\n",
       "      <th>future</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-08-09</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-09</td>\n",
       "      <td>0.909046</td>\n",
       "      <td>1.749289</td>\n",
       "      <td>1.916540</td>\n",
       "      <td>0.794497</td>\n",
       "      <td>0.850151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-10</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-10</td>\n",
       "      <td>0.692321</td>\n",
       "      <td>0.909046</td>\n",
       "      <td>0.909046</td>\n",
       "      <td>0.692321</td>\n",
       "      <td>1.266023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-11</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-11</td>\n",
       "      <td>0.668067</td>\n",
       "      <td>0.692321</td>\n",
       "      <td>0.692321</td>\n",
       "      <td>0.654331</td>\n",
       "      <td>1.951460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-12</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-12</td>\n",
       "      <td>0.850151</td>\n",
       "      <td>0.668067</td>\n",
       "      <td>1.148621</td>\n",
       "      <td>0.668067</td>\n",
       "      <td>1.591219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-08-13</th>\n",
       "      <td>ETH</td>\n",
       "      <td>2015-08-13</td>\n",
       "      <td>1.266023</td>\n",
       "      <td>0.850151</td>\n",
       "      <td>1.266023</td>\n",
       "      <td>0.850151</td>\n",
       "      <td>1.693707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Currency        Date  Closing Price (USD)  24h Open (USD)  \\\n",
       "Date                                                                   \n",
       "2015-08-09      ETH  2015-08-09             0.909046        1.749289   \n",
       "2015-08-10      ETH  2015-08-10             0.692321        0.909046   \n",
       "2015-08-11      ETH  2015-08-11             0.668067        0.692321   \n",
       "2015-08-12      ETH  2015-08-12             0.850151        0.668067   \n",
       "2015-08-13      ETH  2015-08-13             1.266023        0.850151   \n",
       "\n",
       "            24h High (USD)  24h Low (USD)    future  \n",
       "Date                                                 \n",
       "2015-08-09        1.916540       0.794497  0.850151  \n",
       "2015-08-10        0.909046       0.692321  1.266023  \n",
       "2015-08-11        0.692321       0.654331  1.951460  \n",
       "2015-08-12        1.148621       0.668067  1.591219  \n",
       "2015-08-13        1.266023       0.850151  1.693707  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run df thorugh the function to add future coulumn to eth_eval\n",
    "main_df = add_future_column(eth_df)\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape\n",
    "def expand_windowed_data(X1,length_of_sample):\n",
    "    \"\"\"LSTM is expecting a 3-D data structure with (batch number, time steps, features)\"\"\"\n",
    "    X2 = create_rolling_windows(X1, length_of_sample)\n",
    "    X3 = X2.reshape(-1, length_of_sample, X1.shape[1])\n",
    "    return X3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rolling_windows(values, count):\n",
    "    \"\"\"create a set of records that have the first count rows, then the same number of rows offset by one etc.\n",
    "    example=abcdefghijklmn\n",
    "    create_rolling_window(example, 3)\n",
    "    would return abcbcdcdedefefgfghghihijijkjklklmlmn\"\"\"\n",
    "    firstitem = values[:count]\n",
    "    items = [values[window_start:window_start + count] for window_start in range(1, 1 + len(values) - count)]\n",
    "    total = np.append(firstitem, items)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1= main_df[[\"Closing Price (USD)\"]].to_numpy()\n",
    "y1 = main_df[[\"future\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = expand_windowed_data(X1,9)\n",
    "y2 = expand_windowed_data(y1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2176, 1) (2176, 1)\n",
      "(2168, 9, 1) (2168, 9, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X1.shape,y1.shape)\n",
    "print(X2.shape,y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(16, input_shape=shape, return_sequences=True))\n",
    "    model.add(LSTM(16, return_sequences=True))\n",
    "    model.add(Dense(2))\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "68/68 [==============================] - 3s 5ms/step - loss: 535900.8125\n",
      "Epoch 2/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 533987.2500\n",
      "Epoch 3/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 532277.3750\n",
      "Epoch 4/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 531080.1875\n",
      "Epoch 5/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 530038.7500\n",
      "Epoch 6/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 529058.3125\n",
      "Epoch 7/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 528119.6875\n",
      "Epoch 8/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 527210.9375\n",
      "Epoch 9/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 526314.5625\n",
      "Epoch 10/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 525431.4375\n",
      "Epoch 11/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 524560.5625\n",
      "Epoch 12/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 523696.0000\n",
      "Epoch 13/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 522842.4062\n",
      "Epoch 14/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 521991.3125\n",
      "Epoch 15/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 521149.7500\n",
      "Epoch 16/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 520314.3438\n",
      "Epoch 17/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 519483.7500\n",
      "Epoch 18/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 518658.0625\n",
      "Epoch 19/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 517835.7500\n",
      "Epoch 20/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 517022.0000\n",
      "Epoch 21/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 516210.2500\n",
      "Epoch 22/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 515399.6875\n",
      "Epoch 23/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 514599.6250\n",
      "Epoch 24/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 513794.0625\n",
      "Epoch 25/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 512997.0312\n",
      "Epoch 26/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 512197.5000\n",
      "Epoch 27/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 511407.7500\n",
      "Epoch 28/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 510616.9062\n",
      "Epoch 29/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 509826.7188\n",
      "Epoch 30/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 509047.3750\n",
      "Epoch 31/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 508260.4375\n",
      "Epoch 32/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 507485.4688\n",
      "Epoch 33/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 506706.3750\n",
      "Epoch 34/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 505931.2188\n",
      "Epoch 35/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 505161.6250\n",
      "Epoch 36/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 504391.8438\n",
      "Epoch 37/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 503623.0312\n",
      "Epoch 38/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 502859.5000\n",
      "Epoch 39/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 502097.5312\n",
      "Epoch 40/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 501338.8125\n",
      "Epoch 41/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 500577.1875\n",
      "Epoch 42/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 499820.9375\n",
      "Epoch 43/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 499063.1875\n",
      "Epoch 44/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 498312.2812\n",
      "Epoch 45/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 497560.3750\n",
      "Epoch 46/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 496810.9688\n",
      "Epoch 47/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 496062.1562\n",
      "Epoch 48/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 495319.9688\n",
      "Epoch 49/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 494576.0000\n",
      "Epoch 50/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 493834.9062\n",
      "Epoch 51/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 493098.4062\n",
      "Epoch 52/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 492360.5000\n",
      "Epoch 53/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 491627.1875\n",
      "Epoch 54/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 490893.6875\n",
      "Epoch 55/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 490162.5000\n",
      "Epoch 56/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 489435.3438\n",
      "Epoch 57/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 488703.4688\n",
      "Epoch 58/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 487981.4688\n",
      "Epoch 59/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 487257.4062\n",
      "Epoch 60/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 486535.0312\n",
      "Epoch 61/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 485819.2812\n",
      "Epoch 62/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 485102.3750\n",
      "Epoch 63/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 484384.4375\n",
      "Epoch 64/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 483673.4688\n",
      "Epoch 65/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 482958.9688\n",
      "Epoch 66/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 482252.5625\n",
      "Epoch 67/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 481541.4375\n",
      "Epoch 68/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 480837.8438\n",
      "Epoch 69/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 480132.6250\n",
      "Epoch 70/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 479432.5625\n",
      "Epoch 71/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 478730.4062\n",
      "Epoch 72/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 478032.4062\n",
      "Epoch 73/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 477334.9688\n",
      "Epoch 74/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 476638.2188\n",
      "Epoch 75/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 475942.4375\n",
      "Epoch 76/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 475251.4688\n",
      "Epoch 77/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 474559.4375\n",
      "Epoch 78/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 473866.6562\n",
      "Epoch 79/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 473181.2500\n",
      "Epoch 80/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 472495.1250\n",
      "Epoch 81/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 471808.2812\n",
      "Epoch 82/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 471130.2188\n",
      "Epoch 83/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 470446.6875\n",
      "Epoch 84/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 469769.0000\n",
      "Epoch 85/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 469089.5000\n",
      "Epoch 86/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 468414.6875\n",
      "Epoch 87/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 467739.0312\n",
      "Epoch 88/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 467066.8438\n",
      "Epoch 89/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 466399.5312\n",
      "Epoch 90/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 465730.1875\n",
      "Epoch 91/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 465063.9688\n",
      "Epoch 92/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 464399.5625\n",
      "Epoch 93/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 463737.6562\n",
      "Epoch 94/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 463074.3438\n",
      "Epoch 95/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 462417.5938\n",
      "Epoch 96/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 461756.9688\n",
      "Epoch 97/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 461100.4375\n",
      "Epoch 98/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 460445.4375\n",
      "Epoch 99/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 459791.0312\n",
      "Epoch 100/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 459139.2500\n",
      "Epoch 101/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 458487.3750\n",
      "Epoch 102/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 457834.5625\n",
      "Epoch 103/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 457190.1875\n",
      "Epoch 104/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 456541.1875\n",
      "Epoch 105/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 455898.1875\n",
      "Epoch 106/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 455254.6250\n",
      "Epoch 107/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 454614.3438\n",
      "Epoch 108/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 453971.4062\n",
      "Epoch 109/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 453335.5938\n",
      "Epoch 110/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 452696.8438\n",
      "Epoch 111/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 452063.0938\n",
      "Epoch 112/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 451430.3438\n",
      "Epoch 113/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 450797.8125\n",
      "Epoch 114/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 450169.4062\n",
      "Epoch 115/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 449541.2812\n",
      "Epoch 116/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 448911.4375\n",
      "Epoch 117/1000\n",
      "68/68 [==============================] - ETA: 0s - loss: 461918.12 - 0s 5ms/step - loss: 448289.4375\n",
      "Epoch 118/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 447660.0312\n",
      "Epoch 119/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 447039.9062\n",
      "Epoch 120/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 446419.3125\n",
      "Epoch 121/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 445800.1875\n",
      "Epoch 122/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 445183.4375\n",
      "Epoch 123/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 444570.4062\n",
      "Epoch 124/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 443953.3438\n",
      "Epoch 125/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 443340.6562\n",
      "Epoch 126/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 442730.4688\n",
      "Epoch 127/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 442117.8438\n",
      "Epoch 128/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 441509.0625\n",
      "Epoch 129/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 440903.4375\n",
      "Epoch 130/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 440297.5000\n",
      "Epoch 131/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 439691.5938\n",
      "Epoch 132/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 439087.0312\n",
      "Epoch 133/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 438487.9375\n",
      "Epoch 134/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 437885.0000\n",
      "Epoch 135/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 437283.7812\n",
      "Epoch 136/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 436686.8125\n",
      "Epoch 137/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 436089.1875\n",
      "Epoch 138/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 435495.1562\n",
      "Epoch 139/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 434902.2812\n",
      "Epoch 140/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 434311.8125\n",
      "Epoch 141/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 433720.9062\n",
      "Epoch 142/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 433133.0625\n",
      "Epoch 143/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 432546.9062\n",
      "Epoch 144/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 431961.8438\n",
      "Epoch 145/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 431379.7188\n",
      "Epoch 146/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 430793.6562\n",
      "Epoch 147/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 430211.0312\n",
      "Epoch 148/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 429632.1875\n",
      "Epoch 149/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 429054.0625\n",
      "Epoch 150/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 428476.0312\n",
      "Epoch 151/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 427898.3438\n",
      "Epoch 152/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 427326.8438\n",
      "Epoch 153/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 426750.5625\n",
      "Epoch 154/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 426179.1875\n",
      "Epoch 155/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 425608.0000\n",
      "Epoch 156/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 425044.1562\n",
      "Epoch 157/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 424470.5938\n",
      "Epoch 158/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 423906.3438\n",
      "Epoch 159/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 423333.1875\n",
      "Epoch 160/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 422770.0000\n",
      "Epoch 161/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 422205.0625\n",
      "Epoch 162/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 421642.2812\n",
      "Epoch 163/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 421081.1875\n",
      "Epoch 164/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 420520.0938\n",
      "Epoch 165/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 419959.1875\n",
      "Epoch 166/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 419400.4688\n",
      "Epoch 167/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 418841.0625\n",
      "Epoch 168/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 418287.3750\n",
      "Epoch 169/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 417733.1250\n",
      "Epoch 170/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 417178.8750\n",
      "Epoch 171/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 416629.9062\n",
      "Epoch 172/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 416080.2812\n",
      "Epoch 173/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 415530.3125\n",
      "Epoch 174/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 414986.1875\n",
      "Epoch 175/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 414436.9062\n",
      "Epoch 176/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 413893.2812\n",
      "Epoch 177/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 413347.0000\n",
      "Epoch 178/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 412803.1562\n",
      "Epoch 179/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 412261.5938\n",
      "Epoch 180/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 411721.7500\n",
      "Epoch 181/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 411181.8438\n",
      "Epoch 182/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 410642.8750\n",
      "Epoch 183/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 410102.3438\n",
      "Epoch 184/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 409567.9375\n",
      "Epoch 185/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 409029.8438\n",
      "Epoch 186/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 408496.0000\n",
      "Epoch 187/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 407964.0312\n",
      "Epoch 188/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 407430.4375\n",
      "Epoch 189/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 406899.0625\n",
      "Epoch 190/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 406370.6562\n",
      "Epoch 191/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 405838.1250\n",
      "Epoch 192/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 405316.4375\n",
      "Epoch 193/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 404787.9688\n",
      "Epoch 194/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 404261.8750\n",
      "Epoch 195/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 403740.7812\n",
      "Epoch 196/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 403214.6562\n",
      "Epoch 197/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 402693.1250\n",
      "Epoch 198/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 402171.2188\n",
      "Epoch 199/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 401648.5312\n",
      "Epoch 200/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 401130.5000\n",
      "Epoch 201/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 400611.5938\n",
      "Epoch 202/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 400096.7500\n",
      "Epoch 203/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 399578.8438\n",
      "Epoch 204/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 399066.1875\n",
      "Epoch 205/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 398553.9688\n",
      "Epoch 206/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 398040.8750\n",
      "Epoch 207/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 397524.0000\n",
      "Epoch 208/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 397016.9375\n",
      "Epoch 209/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 396508.0938\n",
      "Epoch 210/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 395997.6875\n",
      "Epoch 211/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 395493.7812\n",
      "Epoch 212/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 394992.6250\n",
      "Epoch 213/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 394486.9688\n",
      "Epoch 214/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 393981.9688\n",
      "Epoch 215/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 393480.0938\n",
      "Epoch 216/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 392980.5312\n",
      "Epoch 217/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 392479.7500\n",
      "Epoch 218/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 391977.5938\n",
      "Epoch 219/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 391485.5625\n",
      "Epoch 220/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 390983.4688\n",
      "Epoch 221/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 390489.0000\n",
      "Epoch 222/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 389989.8438\n",
      "Epoch 223/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 389493.8750\n",
      "Epoch 224/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 389001.1875\n",
      "Epoch 225/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 388506.3125\n",
      "Epoch 226/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 388013.4688\n",
      "Epoch 227/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 387526.0000\n",
      "Epoch 228/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 387037.3750\n",
      "Epoch 229/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 386546.7500\n",
      "Epoch 230/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 386053.6875\n",
      "Epoch 231/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 385565.4688\n",
      "Epoch 232/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 385079.7188\n",
      "Epoch 233/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 384598.1562\n",
      "Epoch 234/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 384110.8125\n",
      "Epoch 235/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 383623.4375\n",
      "Epoch 236/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 383136.2188\n",
      "Epoch 237/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 382657.5938\n",
      "Epoch 238/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 382169.4062\n",
      "Epoch 239/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 381690.4062\n",
      "Epoch 240/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 381208.3750\n",
      "Epoch 241/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 380727.5312\n",
      "Epoch 242/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 380243.0938\n",
      "Epoch 243/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 379762.4375\n",
      "Epoch 244/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 379289.3438\n",
      "Epoch 245/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 378809.0625\n",
      "Epoch 246/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 378331.4688\n",
      "Epoch 247/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 377854.9375\n",
      "Epoch 248/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 377380.5312\n",
      "Epoch 249/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 376914.4688\n",
      "Epoch 250/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 376433.0625\n",
      "Epoch 251/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 375964.2812\n",
      "Epoch 252/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 375490.5625\n",
      "Epoch 253/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 375020.2188\n",
      "Epoch 254/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 374548.4688\n",
      "Epoch 255/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 374080.9062\n",
      "Epoch 256/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 373610.7812\n",
      "Epoch 257/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 373146.4062\n",
      "Epoch 258/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 372681.8750\n",
      "Epoch 259/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 372214.2812\n",
      "Epoch 260/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 371750.3750\n",
      "Epoch 261/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 371283.5312\n",
      "Epoch 262/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 370822.3750\n",
      "Epoch 263/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 370359.5000\n",
      "Epoch 264/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 369896.9375\n",
      "Epoch 265/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 369431.4375\n",
      "Epoch 266/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 368974.0938\n",
      "Epoch 267/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 368510.8125\n",
      "Epoch 268/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 368050.4062\n",
      "Epoch 269/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 367594.0938\n",
      "Epoch 270/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 367143.3125\n",
      "Epoch 271/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 366689.6875\n",
      "Epoch 272/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 366236.5312\n",
      "Epoch 273/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 365776.5625\n",
      "Epoch 274/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 365326.8438\n",
      "Epoch 275/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 364871.1562\n",
      "Epoch 276/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 364416.7500\n",
      "Epoch 277/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 363965.0938\n",
      "Epoch 278/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 363514.4062\n",
      "Epoch 279/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 363064.6875\n",
      "Epoch 280/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 362622.9375\n",
      "Epoch 281/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 362171.6875\n",
      "Epoch 282/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 361722.7500\n",
      "Epoch 283/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 361278.2812\n",
      "Epoch 284/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 360834.8125\n",
      "Epoch 285/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 360388.0625\n",
      "Epoch 286/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 359947.7812\n",
      "Epoch 287/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 359508.9062\n",
      "Epoch 288/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 359066.3750\n",
      "Epoch 289/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 358620.0938\n",
      "Epoch 290/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 358179.7812\n",
      "Epoch 291/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 357747.1875\n",
      "Epoch 292/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 357298.5625\n",
      "Epoch 293/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 356862.2500\n",
      "Epoch 294/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 356430.1562\n",
      "Epoch 295/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 355990.7500\n",
      "Epoch 296/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 355554.6875\n",
      "Epoch 297/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 355116.6875\n",
      "Epoch 298/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 354677.1250\n",
      "Epoch 299/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 354242.9375\n",
      "Epoch 300/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 353806.1250\n",
      "Epoch 301/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 353374.8125\n",
      "Epoch 302/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 352944.3750\n",
      "Epoch 303/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 352507.0312\n",
      "Epoch 304/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 352077.6250\n",
      "Epoch 305/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 351646.7188\n",
      "Epoch 306/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 351218.9688\n",
      "Epoch 307/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 350786.5625\n",
      "Epoch 308/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 350358.3438\n",
      "Epoch 309/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 349928.7500\n",
      "Epoch 310/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 349495.1875\n",
      "Epoch 311/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 349067.7500\n",
      "Epoch 312/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 348645.5312\n",
      "Epoch 313/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 348209.3750\n",
      "Epoch 314/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 347787.8125\n",
      "Epoch 315/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 347368.0625\n",
      "Epoch 316/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 346936.8438\n",
      "Epoch 317/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 346514.5625\n",
      "Epoch 318/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 346095.2500\n",
      "Epoch 319/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 345666.6562\n",
      "Epoch 320/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 345243.7500\n",
      "Epoch 321/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 344825.3438\n",
      "Epoch 322/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 344412.0312\n",
      "Epoch 323/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 343984.0625\n",
      "Epoch 324/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 343564.8750\n",
      "Epoch 325/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 343146.0625\n",
      "Epoch 326/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 342729.7500\n",
      "Epoch 327/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 342311.4062\n",
      "Epoch 328/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 341897.8125\n",
      "Epoch 329/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 341485.3750\n",
      "Epoch 330/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 341063.8125\n",
      "Epoch 331/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 340651.9375\n",
      "Epoch 332/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 340230.5625\n",
      "Epoch 333/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 339820.8438\n",
      "Epoch 334/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 339411.5625\n",
      "Epoch 335/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 338988.4062\n",
      "Epoch 336/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 338579.2500\n",
      "Epoch 337/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 338170.1250\n",
      "Epoch 338/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 337760.2500\n",
      "Epoch 339/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 337359.7500\n",
      "Epoch 340/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 336950.4688\n",
      "Epoch 341/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 336541.4375\n",
      "Epoch 342/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 336131.4688\n",
      "Epoch 343/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 335733.3438\n",
      "Epoch 344/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 335331.5312\n",
      "Epoch 345/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 334926.6562\n",
      "Epoch 346/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 334514.2500\n",
      "Epoch 347/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 334113.1562\n",
      "Epoch 348/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 333708.8125\n",
      "Epoch 349/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 333315.5938\n",
      "Epoch 350/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 332918.2500\n",
      "Epoch 351/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 332512.0625\n",
      "Epoch 352/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 332115.2188\n",
      "Epoch 353/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 331704.6875\n",
      "Epoch 354/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 331305.0000\n",
      "Epoch 355/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 330918.1250\n",
      "Epoch 356/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 330516.1562\n",
      "Epoch 357/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 330122.4062\n",
      "Epoch 358/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 329721.4062\n",
      "Epoch 359/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 329336.0625\n",
      "Epoch 360/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 328938.9375\n",
      "Epoch 361/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 328541.0000\n",
      "Epoch 362/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 328147.6875\n",
      "Epoch 363/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 327761.2500\n",
      "Epoch 364/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 327361.5625\n",
      "Epoch 365/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 326966.2500\n",
      "Epoch 366/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 326591.7188\n",
      "Epoch 367/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 326183.8438\n",
      "Epoch 368/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 325794.6250\n",
      "Epoch 369/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 325411.7812\n",
      "Epoch 370/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 325012.0000\n",
      "Epoch 371/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 324620.8438\n",
      "Epoch 372/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 324237.3438\n",
      "Epoch 373/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 323851.3438\n",
      "Epoch 374/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 323457.2188\n",
      "Epoch 375/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 323068.1875\n",
      "Epoch 376/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 322697.8750\n",
      "Epoch 377/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 322311.7188\n",
      "Epoch 378/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 321913.5625\n",
      "Epoch 379/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 321524.9375\n",
      "Epoch 380/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 321148.0000\n",
      "Epoch 381/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 320760.3125\n",
      "Epoch 382/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 320377.1250\n",
      "Epoch 383/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 319995.4688\n",
      "Epoch 384/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 319603.1875: 0s - loss: 2\n",
      "Epoch 385/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 319242.9688\n",
      "Epoch 386/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 318843.6875\n",
      "Epoch 387/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 318457.4688\n",
      "Epoch 388/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 318087.1562\n",
      "Epoch 389/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 317698.9688\n",
      "Epoch 390/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 317320.9062\n",
      "Epoch 391/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 316936.8438\n",
      "Epoch 392/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 316556.1875\n",
      "Epoch 393/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 316174.2812\n",
      "Epoch 394/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 315795.7812\n",
      "Epoch 395/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 315421.5625\n",
      "Epoch 396/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 315042.3438\n",
      "Epoch 397/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 314665.1250\n",
      "Epoch 398/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 314283.4688\n",
      "Epoch 399/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 313913.5938\n",
      "Epoch 400/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 313536.5938\n",
      "Epoch 401/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 313174.7188\n",
      "Epoch 402/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 312790.2188\n",
      "Epoch 403/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 312415.5938\n",
      "Epoch 404/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 312039.5312\n",
      "Epoch 405/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 311679.1875\n",
      "Epoch 406/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 311304.1250\n",
      "Epoch 407/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 310929.9375\n",
      "Epoch 408/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 310552.7500\n",
      "Epoch 409/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 310179.3750\n",
      "Epoch 410/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 309811.6250\n",
      "Epoch 411/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 309454.1250\n",
      "Epoch 412/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 309081.5938\n",
      "Epoch 413/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 308706.8750\n",
      "Epoch 414/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 308342.4062\n",
      "Epoch 415/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 307971.7500\n",
      "Epoch 416/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 307609.1562\n",
      "Epoch 417/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 307235.2812\n",
      "Epoch 418/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 306868.3750\n",
      "Epoch 419/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 306504.3125\n",
      "Epoch 420/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 306153.4062\n",
      "Epoch 421/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 305776.6250\n",
      "Epoch 422/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 305417.0312\n",
      "Epoch 423/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 305074.7500\n",
      "Epoch 424/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 304738.2188\n",
      "Epoch 425/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 304334.6562\n",
      "Epoch 426/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 303977.0000\n",
      "Epoch 427/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 303625.5625\n",
      "Epoch 428/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 303257.3438\n",
      "Epoch 429/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 302903.6562\n",
      "Epoch 430/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 302537.1562\n",
      "Epoch 431/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 302195.5000\n",
      "Epoch 432/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 301825.1875\n",
      "Epoch 433/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 301473.2188\n",
      "Epoch 434/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 301108.1250\n",
      "Epoch 435/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 300766.7500\n",
      "Epoch 436/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 300399.9688\n",
      "Epoch 437/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 300034.0625\n",
      "Epoch 438/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 299701.0000\n",
      "Epoch 439/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 299328.0312\n",
      "Epoch 440/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 298986.3750\n",
      "Epoch 441/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 298620.3438\n",
      "Epoch 442/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 298269.5000\n",
      "Epoch 443/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 297907.2188\n",
      "Epoch 444/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 297559.5625\n",
      "Epoch 445/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 297199.6250\n",
      "Epoch 446/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 296850.5625\n",
      "Epoch 447/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 296518.9062\n",
      "Epoch 448/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 296149.5625\n",
      "Epoch 449/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 295807.9688\n",
      "Epoch 450/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 295442.6250\n",
      "Epoch 451/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 295097.1250\n",
      "Epoch 452/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 294760.9375\n",
      "Epoch 453/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 294426.5000\n",
      "Epoch 454/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 294057.4062\n",
      "Epoch 455/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 293699.7188\n",
      "Epoch 456/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 293385.3750\n",
      "Epoch 457/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 293033.1875\n",
      "Epoch 458/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 292675.8438\n",
      "Epoch 459/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 292320.7188\n",
      "Epoch 460/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 291987.0312\n",
      "Epoch 461/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 291626.6250\n",
      "Epoch 462/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 291282.5625\n",
      "Epoch 463/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 290943.8125\n",
      "Epoch 464/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 290586.5312\n",
      "Epoch 465/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 290265.4688\n",
      "Epoch 466/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 289900.6250\n",
      "Epoch 467/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 289560.9375\n",
      "Epoch 468/1000\n",
      "68/68 [==============================] - 1s 8ms/step - loss: 289220.5312\n",
      "Epoch 469/1000\n",
      "68/68 [==============================] - 1s 9ms/step - loss: 288873.8125\n",
      "Epoch 470/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 288533.5625\n",
      "Epoch 471/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 288215.7812\n",
      "Epoch 472/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 287864.5938\n",
      "Epoch 473/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 287514.6250\n",
      "Epoch 474/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 287190.1562\n",
      "Epoch 475/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 286832.0938\n",
      "Epoch 476/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 286500.1875\n",
      "Epoch 477/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 286156.5938\n",
      "Epoch 478/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 285813.5000\n",
      "Epoch 479/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 285472.8750\n",
      "Epoch 480/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 285149.0625\n",
      "Epoch 481/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 284801.7188\n",
      "Epoch 482/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 284460.3125\n",
      "Epoch 483/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 284132.1875\n",
      "Epoch 484/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 283787.9688\n",
      "Epoch 485/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 283444.2188\n",
      "Epoch 486/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 283121.0938\n",
      "Epoch 487/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 282780.4062\n",
      "Epoch 488/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 282451.7188\n",
      "Epoch 489/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 282120.3438\n",
      "Epoch 490/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 281775.6562\n",
      "Epoch 491/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 281442.4062\n",
      "Epoch 492/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 281119.2500\n",
      "Epoch 493/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 280785.5938\n",
      "Epoch 494/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 280462.1875\n",
      "Epoch 495/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 280130.2188\n",
      "Epoch 496/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 279788.2188\n",
      "Epoch 497/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 279462.5000\n",
      "Epoch 498/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 279141.0625\n",
      "Epoch 499/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 278800.2812\n",
      "Epoch 500/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 278470.4375\n",
      "Epoch 501/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 278136.5312\n",
      "Epoch 502/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 277824.4375\n",
      "Epoch 503/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 277487.8438\n",
      "Epoch 504/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 277150.4375\n",
      "Epoch 505/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 276833.8750\n",
      "Epoch 506/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 276516.5938\n",
      "Epoch 507/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 276172.4062\n",
      "Epoch 508/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 275843.2812\n",
      "Epoch 509/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 275511.3750\n",
      "Epoch 510/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 275203.4688\n",
      "Epoch 511/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 274864.2188\n",
      "Epoch 512/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 274546.6875\n",
      "Epoch 513/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 274215.8750\n",
      "Epoch 514/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 273888.3125\n",
      "Epoch 515/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 273561.8438\n",
      "Epoch 516/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 273233.8438\n",
      "Epoch 517/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 272961.5000\n",
      "Epoch 518/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 272609.3438\n",
      "Epoch 519/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 272285.6562\n",
      "Epoch 520/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 271955.3438\n",
      "Epoch 521/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 271625.2500\n",
      "Epoch 522/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 271310.4375\n",
      "Epoch 523/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 270978.9375\n",
      "Epoch 524/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 270660.2500\n",
      "Epoch 525/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 270365.7500\n",
      "Epoch 526/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 270038.1250\n",
      "Epoch 527/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 269725.3750\n",
      "Epoch 528/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 269379.3438\n",
      "Epoch 529/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 269062.8438\n",
      "Epoch 530/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 268767.4062\n",
      "Epoch 531/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 268429.7500\n",
      "Epoch 532/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 268122.4375\n",
      "Epoch 533/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 267796.1875\n",
      "Epoch 534/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 267483.7500\n",
      "Epoch 535/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 267163.2812\n",
      "Epoch 536/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 266843.7812\n",
      "Epoch 537/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 266544.5000\n",
      "Epoch 538/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 266221.0312\n",
      "Epoch 539/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 265911.7812\n",
      "Epoch 540/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 265590.5312\n",
      "Epoch 541/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 265300.9375\n",
      "Epoch 542/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 264969.2500\n",
      "Epoch 543/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 264660.9375\n",
      "Epoch 544/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 264335.0625\n",
      "Epoch 545/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 264041.9375\n",
      "Epoch 546/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 263714.1562\n",
      "Epoch 547/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 263418.5938\n",
      "Epoch 548/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 263101.7500\n",
      "Epoch 549/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 262800.6250\n",
      "Epoch 550/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 262478.1875\n",
      "Epoch 551/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 262177.8750\n",
      "Epoch 552/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 261866.5938\n",
      "Epoch 553/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 261556.0469\n",
      "Epoch 554/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 261254.7344\n",
      "Epoch 555/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 260930.9219\n",
      "Epoch 556/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 260619.0469\n",
      "Epoch 557/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 260306.9844\n",
      "Epoch 558/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 260006.8750\n",
      "Epoch 559/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 259691.9531\n",
      "Epoch 560/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 259400.9219\n",
      "Epoch 561/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 259113.6562\n",
      "Epoch 562/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 258839.7344\n",
      "Epoch 563/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 258481.7344\n",
      "Epoch 564/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 258191.4688\n",
      "Epoch 565/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 257882.2969\n",
      "Epoch 566/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 257585.4219\n",
      "Epoch 567/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 257265.3594: 0s - loss: 24946\n",
      "Epoch 568/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 256952.7344\n",
      "Epoch 569/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 256663.0781\n",
      "Epoch 570/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 256379.8125\n",
      "Epoch 571/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 256040.5625\n",
      "Epoch 572/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 255740.7188\n",
      "Epoch 573/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 255441.4531\n",
      "Epoch 574/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 255176.7656\n",
      "Epoch 575/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 254848.2344\n",
      "Epoch 576/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 254551.8281\n",
      "Epoch 577/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 254233.5312\n",
      "Epoch 578/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 253926.2031\n",
      "Epoch 579/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 253644.0781\n",
      "Epoch 580/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 253329.9219\n",
      "Epoch 581/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 253054.2656\n",
      "Epoch 582/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 252761.2344\n",
      "Epoch 583/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 252445.6719: 0s - loss: 28268\n",
      "Epoch 584/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 252131.1875\n",
      "Epoch 585/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 251827.4844\n",
      "Epoch 586/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 251539.7812\n",
      "Epoch 587/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 251228.7812\n",
      "Epoch 588/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 250926.9375\n",
      "Epoch 589/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 250638.2031\n",
      "Epoch 590/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 250359.7031\n",
      "Epoch 591/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 250059.9219\n",
      "Epoch 592/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 249760.4062\n",
      "Epoch 593/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 249467.1562\n",
      "Epoch 594/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 249177.6875\n",
      "Epoch 595/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 248884.5156\n",
      "Epoch 596/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 248591.9375\n",
      "Epoch 597/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 248306.5938\n",
      "Epoch 598/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 248006.7031\n",
      "Epoch 599/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 247725.2500\n",
      "Epoch 600/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 247412.8438\n",
      "Epoch 601/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 247144.2344\n",
      "Epoch 602/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 246891.8906\n",
      "Epoch 603/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 246587.1562\n",
      "Epoch 604/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 246288.1406\n",
      "Epoch 605/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 245978.2031\n",
      "Epoch 606/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 245682.6875\n",
      "Epoch 607/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 245396.0938\n",
      "Epoch 608/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 245105.9375\n",
      "Epoch 609/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 244825.5938\n",
      "Epoch 610/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 244511.8906\n",
      "Epoch 611/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 244224.4219\n",
      "Epoch 612/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 243952.2656\n",
      "Epoch 613/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 243656.7500\n",
      "Epoch 614/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 243368.2031\n",
      "Epoch 615/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 243074.1406\n",
      "Epoch 616/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 242797.3281\n",
      "Epoch 617/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 242509.2031\n",
      "Epoch 618/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 242236.0000\n",
      "Epoch 619/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 241942.5156\n",
      "Epoch 620/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 241655.1719\n",
      "Epoch 621/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 241361.0938\n",
      "Epoch 622/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 241085.1719\n",
      "Epoch 623/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 240781.6094\n",
      "Epoch 624/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 240493.0625\n",
      "Epoch 625/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 240246.8281\n",
      "Epoch 626/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 239933.9219\n",
      "Epoch 627/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 239650.4531\n",
      "Epoch 628/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 239360.7500\n",
      "Epoch 629/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 239106.4375\n",
      "Epoch 630/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 238820.2344\n",
      "Epoch 631/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 238511.8750\n",
      "Epoch 632/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 238233.7656: 0s - loss: 24357\n",
      "Epoch 633/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 237948.1406\n",
      "Epoch 634/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 237657.2969\n",
      "Epoch 635/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 237397.9219\n",
      "Epoch 636/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 237122.0156\n",
      "Epoch 637/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 236840.9844\n",
      "Epoch 638/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 236552.4688\n",
      "Epoch 639/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 236261.7344\n",
      "Epoch 640/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 235972.3281\n",
      "Epoch 641/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 235705.7188\n",
      "Epoch 642/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 235447.2344\n",
      "Epoch 643/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 235201.1250\n",
      "Epoch 644/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 234897.3438\n",
      "Epoch 645/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 234570.3125\n",
      "Epoch 646/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 234320.5938\n",
      "Epoch 647/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 234027.8125\n",
      "Epoch 648/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 233745.2344\n",
      "Epoch 649/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 233481.9219\n",
      "Epoch 650/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 233219.9688\n",
      "Epoch 651/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 232916.7188\n",
      "Epoch 652/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 232669.8438\n",
      "Epoch 653/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 232367.6875\n",
      "Epoch 654/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 232111.1719\n",
      "Epoch 655/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 231821.4531\n",
      "Epoch 656/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 231565.3438\n",
      "Epoch 657/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 231285.9531\n",
      "Epoch 658/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 231002.0156\n",
      "Epoch 659/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 230749.0625\n",
      "Epoch 660/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 230454.4219\n",
      "Epoch 661/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 230185.2812\n",
      "Epoch 662/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 229908.1875\n",
      "Epoch 663/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 229648.5312\n",
      "Epoch 664/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 229370.1094\n",
      "Epoch 665/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 229095.1250\n",
      "Epoch 666/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 228858.7344\n",
      "Epoch 667/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 228565.2812\n",
      "Epoch 668/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 228295.4688\n",
      "Epoch 669/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 228013.2031\n",
      "Epoch 670/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 227763.7812\n",
      "Epoch 671/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 227500.9531\n",
      "Epoch 672/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 227201.1250\n",
      "Epoch 673/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 226935.4844\n",
      "Epoch 674/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 226659.3594\n",
      "Epoch 675/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 226425.5469\n",
      "Epoch 676/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 226129.1406\n",
      "Epoch 677/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 225912.6562\n",
      "Epoch 678/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 225579.9531\n",
      "Epoch 679/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 225333.6250\n",
      "Epoch 680/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 225051.7812\n",
      "Epoch 681/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 224801.8750\n",
      "Epoch 682/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 224565.0938\n",
      "Epoch 683/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 224255.6250\n",
      "Epoch 684/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 223981.5938\n",
      "Epoch 685/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 223718.2031\n",
      "Epoch 686/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 223454.7188\n",
      "Epoch 687/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 223182.7969\n",
      "Epoch 688/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 222928.7344\n",
      "Epoch 689/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 222671.8750\n",
      "Epoch 690/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 222388.0312\n",
      "Epoch 691/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 222135.3281\n",
      "Epoch 692/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 221857.1719\n",
      "Epoch 693/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 221609.0625\n",
      "Epoch 694/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 221384.1562\n",
      "Epoch 695/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 221102.2500\n",
      "Epoch 696/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 220829.3594\n",
      "Epoch 697/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 220545.8125\n",
      "Epoch 698/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 220308.9219\n",
      "Epoch 699/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 220049.7188\n",
      "Epoch 700/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 219848.2500\n",
      "Epoch 701/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 219535.8750\n",
      "Epoch 702/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 219251.4062\n",
      "Epoch 703/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 219001.8281\n",
      "Epoch 704/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 218751.8750\n",
      "Epoch 705/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 218480.2656\n",
      "Epoch 706/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 218194.2656\n",
      "Epoch 707/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 217964.9844\n",
      "Epoch 708/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 217714.3438\n",
      "Epoch 709/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 217493.7812\n",
      "Epoch 710/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 217152.3594\n",
      "Epoch 711/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 216925.7500\n",
      "Epoch 712/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 216647.6719\n",
      "Epoch 713/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 216382.9219\n",
      "Epoch 714/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 216188.0312\n",
      "Epoch 715/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 215862.0938\n",
      "Epoch 716/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 215624.5938\n",
      "Epoch 717/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 215395.4531\n",
      "Epoch 718/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 215126.5625\n",
      "Epoch 719/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 214861.1094\n",
      "Epoch 720/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 214579.4531\n",
      "Epoch 721/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 214366.5781\n",
      "Epoch 722/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 214101.2812\n",
      "Epoch 723/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 213891.7344\n",
      "Epoch 724/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 213636.9688\n",
      "Epoch 725/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 213369.0156\n",
      "Epoch 726/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 213065.4219\n",
      "Epoch 727/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 212847.5000\n",
      "Epoch 728/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 212567.4688\n",
      "Epoch 729/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 212317.1719\n",
      "Epoch 730/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 212158.8281\n",
      "Epoch 731/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 211803.9219\n",
      "Epoch 732/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 211597.0000\n",
      "Epoch 733/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 211292.6094\n",
      "Epoch 734/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 211026.3125\n",
      "Epoch 735/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 210751.2188\n",
      "Epoch 736/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 210520.2656\n",
      "Epoch 737/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 210370.8906\n",
      "Epoch 738/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 210058.7500\n",
      "Epoch 739/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 209762.4688\n",
      "Epoch 740/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 209508.8750\n",
      "Epoch 741/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 209303.4531\n",
      "Epoch 742/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 209009.8125\n",
      "Epoch 743/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 208800.0156\n",
      "Epoch 744/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 208534.6562\n",
      "Epoch 745/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 208289.5469\n",
      "Epoch 746/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 208008.0938\n",
      "Epoch 747/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 207770.9688\n",
      "Epoch 748/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 207519.7656\n",
      "Epoch 749/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 207279.3281\n",
      "Epoch 750/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 207079.4531\n",
      "Epoch 751/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 206829.7031\n",
      "Epoch 752/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 206531.3594\n",
      "Epoch 753/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 206314.1094\n",
      "Epoch 754/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 206050.3438\n",
      "Epoch 755/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 205853.8438\n",
      "Epoch 756/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 205583.9844\n",
      "Epoch 757/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 205354.6562\n",
      "Epoch 758/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 205089.0781\n",
      "Epoch 759/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 204823.8594\n",
      "Epoch 760/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 204613.4219\n",
      "Epoch 761/1000\n",
      "68/68 [==============================] - ETA: 0s - loss: 204531.14 - 0s 4ms/step - loss: 204334.9062\n",
      "Epoch 762/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 204109.0625\n",
      "Epoch 763/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 203843.0625\n",
      "Epoch 764/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 203632.2812\n",
      "Epoch 765/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 203364.0938\n",
      "Epoch 766/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 203166.6719\n",
      "Epoch 767/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 202868.0156\n",
      "Epoch 768/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 202925.5156\n",
      "Epoch 769/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 202656.5156\n",
      "Epoch 770/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 202279.0000\n",
      "Epoch 771/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 201990.6094\n",
      "Epoch 772/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 201764.5000\n",
      "Epoch 773/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 201512.9375\n",
      "Epoch 774/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 201210.7188\n",
      "Epoch 775/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 201038.7969\n",
      "Epoch 776/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 200723.0781\n",
      "Epoch 777/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 200469.0000\n",
      "Epoch 778/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 200226.2344\n",
      "Epoch 779/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 199990.7969\n",
      "Epoch 780/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 199768.4062\n",
      "Epoch 781/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 199511.7500\n",
      "Epoch 782/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 199318.0625\n",
      "Epoch 783/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 199047.3125\n",
      "Epoch 784/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 198882.6250\n",
      "Epoch 785/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 198542.1562\n",
      "Epoch 786/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 198297.2188\n",
      "Epoch 787/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 198077.3438\n",
      "Epoch 788/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 197818.7656\n",
      "Epoch 789/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 197605.5625\n",
      "Epoch 790/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 197410.0000\n",
      "Epoch 791/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 197110.5312\n",
      "Epoch 792/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 196959.3281\n",
      "Epoch 793/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 196652.5625\n",
      "Epoch 794/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 196422.4531\n",
      "Epoch 795/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 196152.7812\n",
      "Epoch 796/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 195936.2969\n",
      "Epoch 797/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 195688.1406\n",
      "Epoch 798/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 195498.0781\n",
      "Epoch 799/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 195310.1094\n",
      "Epoch 800/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 194991.3438\n",
      "Epoch 801/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 194782.4688\n",
      "Epoch 802/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 194791.5469\n",
      "Epoch 803/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 194314.8125\n",
      "Epoch 804/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 194086.0938\n",
      "Epoch 805/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 193842.3750\n",
      "Epoch 806/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 193572.2344\n",
      "Epoch 807/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 193363.0625\n",
      "Epoch 808/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 193118.7656\n",
      "Epoch 809/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 192961.2031\n",
      "Epoch 810/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 192627.9844\n",
      "Epoch 811/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 192485.0781\n",
      "Epoch 812/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 192177.1875\n",
      "Epoch 813/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 192000.0938\n",
      "Epoch 814/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 191711.5469\n",
      "Epoch 815/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 191465.4062\n",
      "Epoch 816/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 191255.9062\n",
      "Epoch 817/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 190989.8906\n",
      "Epoch 818/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 190783.5156\n",
      "Epoch 819/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 190621.1094\n",
      "Epoch 820/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 190344.3438\n",
      "Epoch 821/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 190091.7656: 0s - loss: 1\n",
      "Epoch 822/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 189888.0469\n",
      "Epoch 823/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 189628.3750\n",
      "Epoch 824/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 189409.9844\n",
      "Epoch 825/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 189169.0625\n",
      "Epoch 826/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 188983.4844\n",
      "Epoch 827/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 188765.2344\n",
      "Epoch 828/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 188501.7969\n",
      "Epoch 829/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 188279.8281\n",
      "Epoch 830/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 188072.0000\n",
      "Epoch 831/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 187837.1562\n",
      "Epoch 832/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 187600.0469\n",
      "Epoch 833/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 187346.1562\n",
      "Epoch 834/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 187170.5156\n",
      "Epoch 835/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 186945.6250\n",
      "Epoch 836/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 186731.6875\n",
      "Epoch 837/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 186467.9219\n",
      "Epoch 838/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 186226.3281\n",
      "Epoch 839/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 186028.2344\n",
      "Epoch 840/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 185764.2188\n",
      "Epoch 841/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 185587.5312\n",
      "Epoch 842/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 185343.6406\n",
      "Epoch 843/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 185098.0469\n",
      "Epoch 844/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 184866.8438\n",
      "Epoch 845/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 184650.8281\n",
      "Epoch 846/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 184420.5781\n",
      "Epoch 847/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 184226.8594\n",
      "Epoch 848/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 183995.0312\n",
      "Epoch 849/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 183824.9062\n",
      "Epoch 850/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 183527.2656\n",
      "Epoch 851/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 183245.3906\n",
      "Epoch 852/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 183184.0938\n",
      "Epoch 853/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 182856.1875\n",
      "Epoch 854/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 182599.7344\n",
      "Epoch 855/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 182388.1406\n",
      "Epoch 856/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 182230.3438\n",
      "Epoch 857/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 181920.5312\n",
      "Epoch 858/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 181709.0312\n",
      "Epoch 859/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 181473.6406\n",
      "Epoch 860/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 181270.4688\n",
      "Epoch 861/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 181026.6719\n",
      "Epoch 862/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 180818.1406\n",
      "Epoch 863/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 180612.5156\n",
      "Epoch 864/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 180408.0938\n",
      "Epoch 865/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 180148.9062\n",
      "Epoch 866/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 180026.7656\n",
      "Epoch 867/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 179805.0000\n",
      "Epoch 868/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 179504.4688\n",
      "Epoch 869/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 179270.8125\n",
      "Epoch 870/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 179056.7031\n",
      "Epoch 871/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 178837.8438\n",
      "Epoch 872/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 178588.7812\n",
      "Epoch 873/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 178417.8125\n",
      "Epoch 874/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 178152.4062\n",
      "Epoch 875/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 177972.2500\n",
      "Epoch 876/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 177839.0781\n",
      "Epoch 877/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 177519.4375\n",
      "Epoch 878/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 177305.7812\n",
      "Epoch 879/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 177137.4375\n",
      "Epoch 880/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 176868.1562\n",
      "Epoch 881/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 176737.3594\n",
      "Epoch 882/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 176426.2969\n",
      "Epoch 883/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 176188.0781\n",
      "Epoch 884/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 175962.8125\n",
      "Epoch 885/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 175774.1719\n",
      "Epoch 886/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 175561.2031\n",
      "Epoch 887/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 175329.2188\n",
      "Epoch 888/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 175149.2656\n",
      "Epoch 889/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 174904.2500\n",
      "Epoch 890/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 174668.2188\n",
      "Epoch 891/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 174541.0156\n",
      "Epoch 892/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 174243.5156\n",
      "Epoch 893/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 174036.0469\n",
      "Epoch 894/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 173839.8906\n",
      "Epoch 895/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 173601.5625\n",
      "Epoch 896/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 173442.7500\n",
      "Epoch 897/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 173249.5000\n",
      "Epoch 898/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 173000.0938\n",
      "Epoch 899/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 172891.1406\n",
      "Epoch 900/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 172546.4688\n",
      "Epoch 901/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 172319.5781\n",
      "Epoch 902/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 172118.1719\n",
      "Epoch 903/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 171923.1875\n",
      "Epoch 904/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 171682.4219\n",
      "Epoch 905/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 171454.0469\n",
      "Epoch 906/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 171263.5781\n",
      "Epoch 907/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 171135.3125\n",
      "Epoch 908/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 170867.4531\n",
      "Epoch 909/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 170678.6250\n",
      "Epoch 910/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 170468.6875\n",
      "Epoch 911/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 170204.0938\n",
      "Epoch 912/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 170009.7344\n",
      "Epoch 913/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 169819.2344\n",
      "Epoch 914/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 169630.3906\n",
      "Epoch 915/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 169350.3438\n",
      "Epoch 916/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 169149.8125\n",
      "Epoch 917/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 168969.0781\n",
      "Epoch 918/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 168741.6094\n",
      "Epoch 919/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 168516.3125\n",
      "Epoch 920/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 168323.9531\n",
      "Epoch 921/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 168211.7031\n",
      "Epoch 922/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 167883.8906\n",
      "Epoch 923/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 167672.2812\n",
      "Epoch 924/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 167509.0312\n",
      "Epoch 925/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 167346.2812\n",
      "Epoch 926/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 167048.6250\n",
      "Epoch 927/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 166868.0469\n",
      "Epoch 928/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 166660.1562\n",
      "Epoch 929/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 166539.8594\n",
      "Epoch 930/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 166242.0469\n",
      "Epoch 931/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 166185.5938\n",
      "Epoch 932/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 165830.6406\n",
      "Epoch 933/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 165623.0625\n",
      "Epoch 934/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 165484.9531\n",
      "Epoch 935/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 165220.2812\n",
      "Epoch 936/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 165019.4688\n",
      "Epoch 937/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 164844.3594\n",
      "Epoch 938/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 164650.0312\n",
      "Epoch 939/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 164440.8125\n",
      "Epoch 940/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 164300.2812\n",
      "Epoch 941/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 164036.5781\n",
      "Epoch 942/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 163762.9844\n",
      "Epoch 943/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 163720.7344\n",
      "Epoch 944/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 163419.9375\n",
      "Epoch 945/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 163202.2031\n",
      "Epoch 946/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 162979.5781\n",
      "Epoch 947/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 162750.3438\n",
      "Epoch 948/1000\n",
      "68/68 [==============================] - 0s 4ms/step - loss: 162608.3281\n",
      "Epoch 949/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 162359.6875\n",
      "Epoch 950/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 162127.0625\n",
      "Epoch 951/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 161943.2188\n",
      "Epoch 952/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 161748.6562\n",
      "Epoch 953/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 161503.6250\n",
      "Epoch 954/1000\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 161328.4062\n",
      "Epoch 955/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 161109.7656\n",
      "Epoch 956/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 161014.4375\n",
      "Epoch 957/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 160818.3594\n",
      "Epoch 958/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 160548.0312\n",
      "Epoch 959/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 160329.0000\n",
      "Epoch 960/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 160624.4219\n",
      "Epoch 961/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 160027.5312\n",
      "Epoch 962/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 159756.3281\n",
      "Epoch 963/1000\n",
      "68/68 [==============================] - 1s 7ms/step - loss: 159554.1250\n",
      "Epoch 964/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 159408.0156\n",
      "Epoch 965/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 159153.3281\n",
      "Epoch 966/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 158984.9688\n",
      "Epoch 967/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 158749.8125\n",
      "Epoch 968/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 158544.7031\n",
      "Epoch 969/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 158297.9531\n",
      "Epoch 970/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 158140.1562\n",
      "Epoch 971/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 158023.1719\n",
      "Epoch 972/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 157807.7969\n",
      "Epoch 973/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 157600.6719\n",
      "Epoch 974/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 157369.4844\n",
      "Epoch 975/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 157128.4062\n",
      "Epoch 976/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 156911.5469\n",
      "Epoch 977/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 156751.6094\n",
      "Epoch 978/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 156565.7500\n",
      "Epoch 979/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 156352.1250\n",
      "Epoch 980/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 156186.7656\n",
      "Epoch 981/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 156010.7031\n",
      "Epoch 982/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 155987.4844\n",
      "Epoch 983/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 155588.1562\n",
      "Epoch 984/1000\n",
      "68/68 [==============================] - 0s 7ms/step - loss: 155476.6406\n",
      "Epoch 985/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 155286.9062\n",
      "Epoch 986/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 154981.7344\n",
      "Epoch 987/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 154878.7500\n",
      "Epoch 988/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 154644.6250\n",
      "Epoch 989/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 154467.7500\n",
      "Epoch 990/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 154250.9531: 0s - loss: 144\n",
      "Epoch 991/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 154092.9375\n",
      "Epoch 992/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 153858.2812\n",
      "Epoch 993/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 153617.5625\n",
      "Epoch 994/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 153522.5312\n",
      "Epoch 995/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 153287.6250\n",
      "Epoch 996/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 153053.6250\n",
      "Epoch 997/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 152849.4688\n",
      "Epoch 998/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 152808.0312\n",
      "Epoch 999/1000\n",
      "68/68 [==============================] - 0s 5ms/step - loss: 152524.0781\n",
      "Epoch 1000/1000\n",
      "68/68 [==============================] - 0s 6ms/step - loss: 152361.5156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18c2b3ea400>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = create_model(X2.shape[1:3]) #The last two entries in the shape, data has shape (batches, timesteps, features)\n",
    "model.compile(optimizer = \"adam\", loss=\"mse\")\n",
    "model.fit(X2, y2, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X2[-1].reshape((1,9,1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 790.6932 ,  790.4229 ],\n",
       "        [ 985.03406,  984.7013 ],\n",
       "        [1014.81537, 1014.473  ],\n",
       "        [1018.9266 , 1018.58276],\n",
       "        [1019.4861 , 1019.142  ],\n",
       "        [1019.56213, 1019.218  ],\n",
       "        [1019.5724 , 1019.22833],\n",
       "        [1019.5738 , 1019.2298 ],\n",
       "        [1019.574  , 1019.23   ]]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-f63073de2ba0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Recover the original prices instead of the scaled version\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredicted_prices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mreal_prices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'scaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predictions)\n",
    "real_prices = scaler.inverse_transform(y2.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-a8b3caccb84f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Predicted'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Predicted'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-65f4081540c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#add signals column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#main_df['target'] = classify(main_df[\"Predicted\"], main_df[\"future\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Predicted\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"future\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Predicted'"
     ]
    }
   ],
   "source": [
    "#add signals column \n",
    "#main_df['target'] = classify(main_df[\"Predicted\"], main_df[\"future\"]) \n",
    "main_df['target'] = main_df[\"Predicted\"] - main_df[\"future\"]\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ef make_target(main_df):\n",
    "#   for val in main_df['target']:\n",
    " #      if val >= 0: \n",
    " #      val = 1\n",
    " #      else: val=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df['buy_signal'] = main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'target'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2894\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2895\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-4496e7381d45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmain_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2895\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2899\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'target'"
     ]
    }
   ],
   "source": [
    "for val, i in main_df['target']:\n",
    "    print(val)\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
