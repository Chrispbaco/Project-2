{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set path to CSV and read in CSV\n",
    "csv_path = Path(\"DATA/DOGE/DOGE_DATA.csv\")\n",
    "doge_df=pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Currency</th>\n",
       "      <th>Date</th>\n",
       "      <th>Closing Price (USD)</th>\n",
       "      <th>24h Open (USD)</th>\n",
       "      <th>24h High (USD)</th>\n",
       "      <th>24h Low (USD)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-27</th>\n",
       "      <td>DOGE</td>\n",
       "      <td>2019-02-27</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.001963</td>\n",
       "      <td>0.001908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>DOGE</td>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.001896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-01</th>\n",
       "      <td>DOGE</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.001977</td>\n",
       "      <td>0.001911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-02</th>\n",
       "      <td>DOGE</td>\n",
       "      <td>2019-03-02</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.001980</td>\n",
       "      <td>0.001940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-03</th>\n",
       "      <td>DOGE</td>\n",
       "      <td>2019-03-03</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.001940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-04</th>\n",
       "      <td>DOGE</td>\n",
       "      <td>2019-03-04</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.001893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-05</th>\n",
       "      <td>DOGE</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.001891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-06</th>\n",
       "      <td>DOGE</td>\n",
       "      <td>2019-03-06</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.001939</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.001919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-07</th>\n",
       "      <td>DOGE</td>\n",
       "      <td>2019-03-07</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.001927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-08</th>\n",
       "      <td>DOGE</td>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>0.001926</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.001909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Currency        Date  Closing Price (USD)  24h Open (USD)  \\\n",
       "Date                                                                   \n",
       "2019-02-27     DOGE  2019-02-27             0.001944        0.001962   \n",
       "2019-02-28     DOGE  2019-02-28             0.001912        0.001944   \n",
       "2019-03-01     DOGE  2019-03-01             0.001956        0.001912   \n",
       "2019-03-02     DOGE  2019-03-02             0.001970        0.001957   \n",
       "2019-03-03     DOGE  2019-03-03             0.001948        0.001970   \n",
       "2019-03-04     DOGE  2019-03-04             0.001900        0.001948   \n",
       "2019-03-05     DOGE  2019-03-05             0.001939        0.001902   \n",
       "2019-03-06     DOGE  2019-03-06             0.001931        0.001939   \n",
       "2019-03-07     DOGE  2019-03-07             0.001944        0.001931   \n",
       "2019-03-08     DOGE  2019-03-08             0.001926        0.001944   \n",
       "\n",
       "            24h High (USD)  24h Low (USD)  \n",
       "Date                                       \n",
       "2019-02-27        0.001963       0.001908  \n",
       "2019-02-28        0.001955       0.001896  \n",
       "2019-03-01        0.001977       0.001911  \n",
       "2019-03-02        0.001980       0.001940  \n",
       "2019-03-03        0.001989       0.001940  \n",
       "2019-03-04        0.001960       0.001893  \n",
       "2019-03-05        0.001964       0.001891  \n",
       "2019-03-06        0.001961       0.001919  \n",
       "2019-03-07        0.001990       0.001927  \n",
       "2019-03-08        0.001966       0.001909  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Set index as Date\n",
    "doge_df = doge_df.set_index(pd.to_datetime(doge_df[\"Date\"], infer_datetime_format=True))\n",
    "\n",
    "# Display sample data\n",
    "doge_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for na\n",
    "doge_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed to (2)\n",
    "from numpy.random import seed\n",
    "\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window):\n",
    "        features = df.iloc[i : (i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X sample values:\n",
      "[[0.00194413 0.00191243 0.00195579 0.00196963 0.00194837 0.0018997\n",
      "  0.0019386  0.00193116 0.0019439  0.00192575 0.00195179 0.00195127\n",
      "  0.0019291  0.00199423 0.0019794  0.00201348 0.00202135 0.00204606\n",
      "  0.0020523  0.00204451 0.00204142 0.00202512 0.00202262 0.00200737\n",
      "  0.00200919 0.00200528 0.00201154 0.00203147 0.00205462 0.00204445\n",
      "  0.00208126 0.00207596 0.00206667 0.00241034 0.00292721 0.003173\n",
      "  0.00364039 0.00352948 0.00336789 0.00339882 0.00294825 0.00287584\n",
      "  0.00296385 0.00274343 0.00281366 0.0028431  0.00286845 0.00274786\n",
      "  0.00277609 0.0027763  0.00295894 0.00289124 0.00285828 0.00275998\n",
      "  0.00276394 0.00276767 0.00256035 0.00241539 0.00252244 0.00253833\n",
      "  0.00243369 0.00241323 0.00248825 0.00245055 0.00254029 0.00267698\n",
      "  0.00267155 0.0025769  0.00256247 0.00252779 0.00253745 0.00246249\n",
      "  0.00254303 0.00275622 0.00263807 0.00272007 0.00301285 0.00328175\n",
      "  0.00319722 0.00289653 0.00299698 0.00312798 0.00297548 0.00304195\n",
      "  0.00291579 0.00295498 0.00301222 0.0030586  0.00304516 0.0031297\n",
      "  0.00315526 0.00321008 0.00321412 0.00340477 0.00336021 0.00332395\n",
      "  0.00322468 0.00297652 0.00302772 0.00301459]\n",
      " [0.00191243 0.00195579 0.00196963 0.00194837 0.0018997  0.0019386\n",
      "  0.00193116 0.0019439  0.00192575 0.00195179 0.00195127 0.0019291\n",
      "  0.00199423 0.0019794  0.00201348 0.00202135 0.00204606 0.0020523\n",
      "  0.00204451 0.00204142 0.00202512 0.00202262 0.00200737 0.00200919\n",
      "  0.00200528 0.00201154 0.00203147 0.00205462 0.00204445 0.00208126\n",
      "  0.00207596 0.00206667 0.00241034 0.00292721 0.003173   0.00364039\n",
      "  0.00352948 0.00336789 0.00339882 0.00294825 0.00287584 0.00296385\n",
      "  0.00274343 0.00281366 0.0028431  0.00286845 0.00274786 0.00277609\n",
      "  0.0027763  0.00295894 0.00289124 0.00285828 0.00275998 0.00276394\n",
      "  0.00276767 0.00256035 0.00241539 0.00252244 0.00253833 0.00243369\n",
      "  0.00241323 0.00248825 0.00245055 0.00254029 0.00267698 0.00267155\n",
      "  0.0025769  0.00256247 0.00252779 0.00253745 0.00246249 0.00254303\n",
      "  0.00275622 0.00263807 0.00272007 0.00301285 0.00328175 0.00319722\n",
      "  0.00289653 0.00299698 0.00312798 0.00297548 0.00304195 0.00291579\n",
      "  0.00295498 0.00301222 0.0030586  0.00304516 0.0031297  0.00315526\n",
      "  0.00321008 0.00321412 0.00340477 0.00336021 0.00332395 0.00322468\n",
      "  0.00297652 0.00302772 0.00301459 0.00312935]\n",
      " [0.00195579 0.00196963 0.00194837 0.0018997  0.0019386  0.00193116\n",
      "  0.0019439  0.00192575 0.00195179 0.00195127 0.0019291  0.00199423\n",
      "  0.0019794  0.00201348 0.00202135 0.00204606 0.0020523  0.00204451\n",
      "  0.00204142 0.00202512 0.00202262 0.00200737 0.00200919 0.00200528\n",
      "  0.00201154 0.00203147 0.00205462 0.00204445 0.00208126 0.00207596\n",
      "  0.00206667 0.00241034 0.00292721 0.003173   0.00364039 0.00352948\n",
      "  0.00336789 0.00339882 0.00294825 0.00287584 0.00296385 0.00274343\n",
      "  0.00281366 0.0028431  0.00286845 0.00274786 0.00277609 0.0027763\n",
      "  0.00295894 0.00289124 0.00285828 0.00275998 0.00276394 0.00276767\n",
      "  0.00256035 0.00241539 0.00252244 0.00253833 0.00243369 0.00241323\n",
      "  0.00248825 0.00245055 0.00254029 0.00267698 0.00267155 0.0025769\n",
      "  0.00256247 0.00252779 0.00253745 0.00246249 0.00254303 0.00275622\n",
      "  0.00263807 0.00272007 0.00301285 0.00328175 0.00319722 0.00289653\n",
      "  0.00299698 0.00312798 0.00297548 0.00304195 0.00291579 0.00295498\n",
      "  0.00301222 0.0030586  0.00304516 0.0031297  0.00315526 0.00321008\n",
      "  0.00321412 0.00340477 0.00336021 0.00332395 0.00322468 0.00297652\n",
      "  0.00302772 0.00301459 0.00312935 0.00302067]] \n",
      "\n",
      "y sample values:\n",
      "[[0.00312935]\n",
      " [0.00302067]\n",
      " [0.00295865]]\n"
     ]
    }
   ],
   "source": [
    "# Define the window size\n",
    "window_size = 100\n",
    "\n",
    "# Set the index of the feature and target columns\n",
    "feature_column = 2\n",
    "target_column = 2\n",
    "\n",
    "# Create the features (X) and target (y) data using the window_data() function.\n",
    "X, y = window_data(doge_df, window_size, feature_column, target_column)\n",
    "\n",
    "# Print a few sample values from X and y\n",
    "print (f\"X sample values:\\n{X[:3]} \\n\")\n",
    "print (f\"y sample values:\\n{y[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Manually splitting the data\n",
    "split = int(0.7 * len(X))\n",
    "\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Importing the MinMaxScaler from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the MinMaxScaler object with the features data X\n",
    "scaler.fit(X)\n",
    "\n",
    "# Scale the features training and testing sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the MinMaxScaler object with the target data Y\n",
    "scaler.fit(y)\n",
    "\n",
    "# Scale the target training and testing sets\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train sample values:\n",
      "[[[0.00095741]\n",
      "  [0.00079557]\n",
      "  [0.00090006]\n",
      "  [0.0009334 ]\n",
      "  [0.00088217]\n",
      "  [0.0007649 ]\n",
      "  [0.00085863]\n",
      "  [0.00084071]\n",
      "  [0.00087141]\n",
      "  [0.00082767]\n",
      "  [0.00089042]\n",
      "  [0.00088917]\n",
      "  [0.00083574]\n",
      "  [0.00099269]\n",
      "  [0.00095696]\n",
      "  [0.00099162]\n",
      "  [0.00081167]\n",
      "  [0.00072461]\n",
      "  [0.00073436]\n",
      "  [0.00064131]\n",
      "  [0.00063701]\n",
      "  [0.0006144 ]\n",
      "  [0.00061093]\n",
      "  [0.00058978]\n",
      "  [0.00059231]\n",
      "  [0.00058688]\n",
      "  [0.00059556]\n",
      "  [0.00062321]\n",
      "  [0.00065533]\n",
      "  [0.00064122]\n",
      "  [0.0006923 ]\n",
      "  [0.00068494]\n",
      "  [0.00067206]\n",
      "  [0.00114888]\n",
      "  [0.00186603]\n",
      "  [0.00220706]\n",
      "  [0.00285553]\n",
      "  [0.00270165]\n",
      "  [0.00247745]\n",
      "  [0.00252036]\n",
      "  [0.00189522]\n",
      "  [0.00179475]\n",
      "  [0.00191687]\n",
      "  [0.00161104]\n",
      "  [0.00170848]\n",
      "  [0.00174932]\n",
      "  [0.0017845 ]\n",
      "  [0.00161719]\n",
      "  [0.00165635]\n",
      "  [0.00165665]\n",
      "  [0.00191006]\n",
      "  [0.00181612]\n",
      "  [0.00177039]\n",
      "  [0.001634  ]\n",
      "  [0.00163949]\n",
      "  [0.00164467]\n",
      "  [0.00135702]\n",
      "  [0.00115589]\n",
      "  [0.00130442]\n",
      "  [0.00132646]\n",
      "  [0.00118129]\n",
      "  [0.00115289]\n",
      "  [0.00125698]\n",
      "  [0.00120467]\n",
      "  [0.00132919]\n",
      "  [0.00151884]\n",
      "  [0.0015113 ]\n",
      "  [0.00137998]\n",
      "  [0.00135996]\n",
      "  [0.00131184]\n",
      "  [0.00132525]\n",
      "  [0.00122125]\n",
      "  [0.00133298]\n",
      "  [0.00162878]\n",
      "  [0.00146485]\n",
      "  [0.00157863]\n",
      "  [0.00198485]\n",
      "  [0.00235793]\n",
      "  [0.00224065]\n",
      "  [0.00182346]\n",
      "  [0.00196283]\n",
      "  [0.00214458]\n",
      "  [0.00193299]\n",
      "  [0.00202522]\n",
      "  [0.00185018]\n",
      "  [0.00190455]\n",
      "  [0.00198398]\n",
      "  [0.00204833]\n",
      "  [0.00202968]\n",
      "  [0.00214697]\n",
      "  [0.00218244]\n",
      "  [0.0022585 ]\n",
      "  [0.0022641 ]\n",
      "  [0.00252862]\n",
      "  [0.0024668 ]\n",
      "  [0.00241649]\n",
      "  [0.00227876]\n",
      "  [0.00193444]\n",
      "  [0.00200547]\n",
      "  [0.00198727]]\n",
      "\n",
      " [[0.00087352]\n",
      "  [0.00090006]\n",
      "  [0.0009334 ]\n",
      "  [0.00088217]\n",
      "  [0.0007649 ]\n",
      "  [0.00085863]\n",
      "  [0.00084071]\n",
      "  [0.00087141]\n",
      "  [0.00082767]\n",
      "  [0.00089042]\n",
      "  [0.00088917]\n",
      "  [0.00083574]\n",
      "  [0.00099269]\n",
      "  [0.00095696]\n",
      "  [0.00103909]\n",
      "  [0.00100971]\n",
      "  [0.00085735]\n",
      "  [0.00073436]\n",
      "  [0.00072219]\n",
      "  [0.00063701]\n",
      "  [0.0006144 ]\n",
      "  [0.00061093]\n",
      "  [0.00058978]\n",
      "  [0.00059231]\n",
      "  [0.00058688]\n",
      "  [0.00059556]\n",
      "  [0.00062321]\n",
      "  [0.00065533]\n",
      "  [0.00064122]\n",
      "  [0.0006923 ]\n",
      "  [0.00068494]\n",
      "  [0.00067206]\n",
      "  [0.00114888]\n",
      "  [0.00186603]\n",
      "  [0.00220706]\n",
      "  [0.00285553]\n",
      "  [0.00270165]\n",
      "  [0.00247745]\n",
      "  [0.00252036]\n",
      "  [0.00189522]\n",
      "  [0.00179475]\n",
      "  [0.00191687]\n",
      "  [0.00161104]\n",
      "  [0.00170848]\n",
      "  [0.00174932]\n",
      "  [0.0017845 ]\n",
      "  [0.00161719]\n",
      "  [0.00165635]\n",
      "  [0.00165665]\n",
      "  [0.00191006]\n",
      "  [0.00181612]\n",
      "  [0.00177039]\n",
      "  [0.001634  ]\n",
      "  [0.00163949]\n",
      "  [0.00164467]\n",
      "  [0.00135702]\n",
      "  [0.00115589]\n",
      "  [0.00130442]\n",
      "  [0.00132646]\n",
      "  [0.00118129]\n",
      "  [0.00115289]\n",
      "  [0.00125698]\n",
      "  [0.00120467]\n",
      "  [0.00132919]\n",
      "  [0.00151884]\n",
      "  [0.0015113 ]\n",
      "  [0.00137998]\n",
      "  [0.00135996]\n",
      "  [0.00131184]\n",
      "  [0.00132525]\n",
      "  [0.00122125]\n",
      "  [0.00133298]\n",
      "  [0.00162878]\n",
      "  [0.00146485]\n",
      "  [0.00157863]\n",
      "  [0.00198485]\n",
      "  [0.00235793]\n",
      "  [0.00224065]\n",
      "  [0.00182346]\n",
      "  [0.00196283]\n",
      "  [0.00214458]\n",
      "  [0.00193299]\n",
      "  [0.00202522]\n",
      "  [0.00185018]\n",
      "  [0.00190455]\n",
      "  [0.00198398]\n",
      "  [0.00204833]\n",
      "  [0.00202968]\n",
      "  [0.00214697]\n",
      "  [0.00218244]\n",
      "  [0.0022585 ]\n",
      "  [0.0022641 ]\n",
      "  [0.00252862]\n",
      "  [0.0024668 ]\n",
      "  [0.00241649]\n",
      "  [0.00227876]\n",
      "  [0.00193444]\n",
      "  [0.00200547]\n",
      "  [0.00198727]\n",
      "  [0.00214649]]\n",
      "\n",
      " [[0.00098825]\n",
      "  [0.0009334 ]\n",
      "  [0.00088217]\n",
      "  [0.0007649 ]\n",
      "  [0.00085863]\n",
      "  [0.00084071]\n",
      "  [0.00087141]\n",
      "  [0.00082767]\n",
      "  [0.00089042]\n",
      "  [0.00088917]\n",
      "  [0.00083574]\n",
      "  [0.00099269]\n",
      "  [0.00095696]\n",
      "  [0.00103909]\n",
      "  [0.00105805]\n",
      "  [0.00106653]\n",
      "  [0.00086889]\n",
      "  [0.00072219]\n",
      "  [0.00071735]\n",
      "  [0.0006144 ]\n",
      "  [0.00061093]\n",
      "  [0.00058978]\n",
      "  [0.00059231]\n",
      "  [0.00058688]\n",
      "  [0.00059556]\n",
      "  [0.00062321]\n",
      "  [0.00065533]\n",
      "  [0.00064122]\n",
      "  [0.0006923 ]\n",
      "  [0.00068494]\n",
      "  [0.00067206]\n",
      "  [0.00114888]\n",
      "  [0.00186603]\n",
      "  [0.00220706]\n",
      "  [0.00285553]\n",
      "  [0.00270165]\n",
      "  [0.00247745]\n",
      "  [0.00252036]\n",
      "  [0.00189522]\n",
      "  [0.00179475]\n",
      "  [0.00191687]\n",
      "  [0.00161104]\n",
      "  [0.00170848]\n",
      "  [0.00174932]\n",
      "  [0.0017845 ]\n",
      "  [0.00161719]\n",
      "  [0.00165635]\n",
      "  [0.00165665]\n",
      "  [0.00191006]\n",
      "  [0.00181612]\n",
      "  [0.00177039]\n",
      "  [0.001634  ]\n",
      "  [0.00163949]\n",
      "  [0.00164467]\n",
      "  [0.00135702]\n",
      "  [0.00115589]\n",
      "  [0.00130442]\n",
      "  [0.00132646]\n",
      "  [0.00118129]\n",
      "  [0.00115289]\n",
      "  [0.00125698]\n",
      "  [0.00120467]\n",
      "  [0.00132919]\n",
      "  [0.00151884]\n",
      "  [0.0015113 ]\n",
      "  [0.00137998]\n",
      "  [0.00135996]\n",
      "  [0.00131184]\n",
      "  [0.00132525]\n",
      "  [0.00122125]\n",
      "  [0.00133298]\n",
      "  [0.00162878]\n",
      "  [0.00146485]\n",
      "  [0.00157863]\n",
      "  [0.00198485]\n",
      "  [0.00235793]\n",
      "  [0.00224065]\n",
      "  [0.00182346]\n",
      "  [0.00196283]\n",
      "  [0.00214458]\n",
      "  [0.00193299]\n",
      "  [0.00202522]\n",
      "  [0.00185018]\n",
      "  [0.00190455]\n",
      "  [0.00198398]\n",
      "  [0.00204833]\n",
      "  [0.00202968]\n",
      "  [0.00214697]\n",
      "  [0.00218244]\n",
      "  [0.0022585 ]\n",
      "  [0.0022641 ]\n",
      "  [0.00252862]\n",
      "  [0.0024668 ]\n",
      "  [0.00241649]\n",
      "  [0.00227876]\n",
      "  [0.00193444]\n",
      "  [0.00200547]\n",
      "  [0.00198727]\n",
      "  [0.00214649]\n",
      "  [0.00199569]]] \n",
      "\n",
      "X_test sample values:\n",
      "[[[0.00422623]\n",
      "  [0.00401392]\n",
      "  [0.00409348]\n",
      "  [0.00414991]\n",
      "  [0.00390717]\n",
      "  [0.00399483]\n",
      "  [0.00369782]\n",
      "  [0.00322743]\n",
      "  [0.00321949]\n",
      "  [0.00276663]\n",
      "  [0.00284375]\n",
      "  [0.00302809]\n",
      "  [0.00274925]\n",
      "  [0.0029416 ]\n",
      "  [0.00293053]\n",
      "  [0.00279053]\n",
      "  [0.00223275]\n",
      "  [0.0018476 ]\n",
      "  [0.00187459]\n",
      "  [0.00172265]\n",
      "  [0.00167742]\n",
      "  [0.00167968]\n",
      "  [0.00168643]\n",
      "  [0.00167665]\n",
      "  [0.00162358]\n",
      "  [0.00150372]\n",
      "  [0.00143726]\n",
      "  [0.00135483]\n",
      "  [0.00145763]\n",
      "  [0.00153087]\n",
      "  [0.00155447]\n",
      "  [0.00155858]\n",
      "  [0.00150554]\n",
      "  [0.00151491]\n",
      "  [0.0014507 ]\n",
      "  [0.00145566]\n",
      "  [0.00141401]\n",
      "  [0.00138987]\n",
      "  [0.00142905]\n",
      "  [0.00142118]\n",
      "  [0.00140703]\n",
      "  [0.00139517]\n",
      "  [0.00144128]\n",
      "  [0.00148738]\n",
      "  [0.00153601]\n",
      "  [0.00153238]\n",
      "  [0.001567  ]\n",
      "  [0.0014707 ]\n",
      "  [0.0014846 ]\n",
      "  [0.00142344]\n",
      "  [0.00139633]\n",
      "  [0.00136537]\n",
      "  [0.00140539]\n",
      "  [0.00140163]\n",
      "  [0.0014071 ]\n",
      "  [0.00152492]\n",
      "  [0.00152229]\n",
      "  [0.00149464]\n",
      "  [0.00148856]\n",
      "  [0.00152605]\n",
      "  [0.00150283]\n",
      "  [0.00154468]\n",
      "  [0.00135652]\n",
      "  [0.00139229]\n",
      "  [0.0013973 ]\n",
      "  [0.00141856]\n",
      "  [0.00137876]\n",
      "  [0.00127808]\n",
      "  [0.00128022]\n",
      "  [0.00134806]\n",
      "  [0.00152204]\n",
      "  [0.00156484]\n",
      "  [0.0015176 ]\n",
      "  [0.00153561]\n",
      "  [0.00152379]\n",
      "  [0.00175222]\n",
      "  [0.00162188]\n",
      "  [0.00165739]\n",
      "  [0.00172225]\n",
      "  [0.00164206]\n",
      "  [0.00166503]\n",
      "  [0.00179949]\n",
      "  [0.00185256]\n",
      "  [0.00188496]\n",
      "  [0.00183347]\n",
      "  [0.00204109]\n",
      "  [0.00264644]\n",
      "  [0.00256659]\n",
      "  [0.00258808]\n",
      "  [0.00327053]\n",
      "  [0.00297116]\n",
      "  [0.00232728]\n",
      "  [0.0023741 ]\n",
      "  [0.00256369]\n",
      "  [0.00256679]\n",
      "  [0.00275756]\n",
      "  [0.00250072]\n",
      "  [0.00248865]\n",
      "  [0.00251475]\n",
      "  [0.00241427]]\n",
      "\n",
      " [[0.00440722]\n",
      "  [0.00409348]\n",
      "  [0.00414991]\n",
      "  [0.00390717]\n",
      "  [0.00399483]\n",
      "  [0.00369782]\n",
      "  [0.00322743]\n",
      "  [0.00321949]\n",
      "  [0.00276663]\n",
      "  [0.00284375]\n",
      "  [0.00302809]\n",
      "  [0.00274925]\n",
      "  [0.0029416 ]\n",
      "  [0.00293053]\n",
      "  [0.00292412]\n",
      "  [0.00277752]\n",
      "  [0.00218606]\n",
      "  [0.00187459]\n",
      "  [0.0019399 ]\n",
      "  [0.00167742]\n",
      "  [0.00167968]\n",
      "  [0.00168643]\n",
      "  [0.00167665]\n",
      "  [0.00162358]\n",
      "  [0.00150372]\n",
      "  [0.00143726]\n",
      "  [0.00135483]\n",
      "  [0.00145763]\n",
      "  [0.00153087]\n",
      "  [0.00155447]\n",
      "  [0.00155858]\n",
      "  [0.00150554]\n",
      "  [0.00151491]\n",
      "  [0.0014507 ]\n",
      "  [0.00145566]\n",
      "  [0.00141401]\n",
      "  [0.00138987]\n",
      "  [0.00142905]\n",
      "  [0.00142118]\n",
      "  [0.00140703]\n",
      "  [0.00139517]\n",
      "  [0.00144128]\n",
      "  [0.00148738]\n",
      "  [0.00153601]\n",
      "  [0.00153238]\n",
      "  [0.001567  ]\n",
      "  [0.0014707 ]\n",
      "  [0.0014846 ]\n",
      "  [0.00142344]\n",
      "  [0.00139633]\n",
      "  [0.00136537]\n",
      "  [0.00140539]\n",
      "  [0.00140163]\n",
      "  [0.0014071 ]\n",
      "  [0.00152492]\n",
      "  [0.00152229]\n",
      "  [0.00149464]\n",
      "  [0.00148856]\n",
      "  [0.00152605]\n",
      "  [0.00150283]\n",
      "  [0.00154468]\n",
      "  [0.00135652]\n",
      "  [0.00139229]\n",
      "  [0.0013973 ]\n",
      "  [0.00141856]\n",
      "  [0.00137876]\n",
      "  [0.00127808]\n",
      "  [0.00128022]\n",
      "  [0.00134806]\n",
      "  [0.00152204]\n",
      "  [0.00156484]\n",
      "  [0.0015176 ]\n",
      "  [0.00153561]\n",
      "  [0.00152379]\n",
      "  [0.00175222]\n",
      "  [0.00162188]\n",
      "  [0.00165739]\n",
      "  [0.00172225]\n",
      "  [0.00164206]\n",
      "  [0.00166503]\n",
      "  [0.00179949]\n",
      "  [0.00185256]\n",
      "  [0.00188496]\n",
      "  [0.00183347]\n",
      "  [0.00204109]\n",
      "  [0.00264644]\n",
      "  [0.00256659]\n",
      "  [0.00258808]\n",
      "  [0.00327053]\n",
      "  [0.00297116]\n",
      "  [0.00232728]\n",
      "  [0.0023741 ]\n",
      "  [0.00256369]\n",
      "  [0.00256679]\n",
      "  [0.00275756]\n",
      "  [0.00250072]\n",
      "  [0.00248865]\n",
      "  [0.00251475]\n",
      "  [0.00241427]\n",
      "  [0.00252382]]\n",
      "\n",
      " [[0.00449457]\n",
      "  [0.00414991]\n",
      "  [0.00390717]\n",
      "  [0.00399483]\n",
      "  [0.00369782]\n",
      "  [0.00322743]\n",
      "  [0.00321949]\n",
      "  [0.00276663]\n",
      "  [0.00284375]\n",
      "  [0.00302809]\n",
      "  [0.00274925]\n",
      "  [0.0029416 ]\n",
      "  [0.00293053]\n",
      "  [0.00292412]\n",
      "  [0.00291049]\n",
      "  [0.00271944]\n",
      "  [0.002218  ]\n",
      "  [0.0019399 ]\n",
      "  [0.00188897]\n",
      "  [0.00167968]\n",
      "  [0.00168643]\n",
      "  [0.00167665]\n",
      "  [0.00162358]\n",
      "  [0.00150372]\n",
      "  [0.00143726]\n",
      "  [0.00135483]\n",
      "  [0.00145763]\n",
      "  [0.00153087]\n",
      "  [0.00155447]\n",
      "  [0.00155858]\n",
      "  [0.00150554]\n",
      "  [0.00151491]\n",
      "  [0.0014507 ]\n",
      "  [0.00145566]\n",
      "  [0.00141401]\n",
      "  [0.00138987]\n",
      "  [0.00142905]\n",
      "  [0.00142118]\n",
      "  [0.00140703]\n",
      "  [0.00139517]\n",
      "  [0.00144128]\n",
      "  [0.00148738]\n",
      "  [0.00153601]\n",
      "  [0.00153238]\n",
      "  [0.001567  ]\n",
      "  [0.0014707 ]\n",
      "  [0.0014846 ]\n",
      "  [0.00142344]\n",
      "  [0.00139633]\n",
      "  [0.00136537]\n",
      "  [0.00140539]\n",
      "  [0.00140163]\n",
      "  [0.0014071 ]\n",
      "  [0.00152492]\n",
      "  [0.00152229]\n",
      "  [0.00149464]\n",
      "  [0.00148856]\n",
      "  [0.00152605]\n",
      "  [0.00150283]\n",
      "  [0.00154468]\n",
      "  [0.00135652]\n",
      "  [0.00139229]\n",
      "  [0.0013973 ]\n",
      "  [0.00141856]\n",
      "  [0.00137876]\n",
      "  [0.00127808]\n",
      "  [0.00128022]\n",
      "  [0.00134806]\n",
      "  [0.00152204]\n",
      "  [0.00156484]\n",
      "  [0.0015176 ]\n",
      "  [0.00153561]\n",
      "  [0.00152379]\n",
      "  [0.00175222]\n",
      "  [0.00162188]\n",
      "  [0.00165739]\n",
      "  [0.00172225]\n",
      "  [0.00164206]\n",
      "  [0.00166503]\n",
      "  [0.00179949]\n",
      "  [0.00185256]\n",
      "  [0.00188496]\n",
      "  [0.00183347]\n",
      "  [0.00204109]\n",
      "  [0.00264644]\n",
      "  [0.00256659]\n",
      "  [0.00258808]\n",
      "  [0.00327053]\n",
      "  [0.00297116]\n",
      "  [0.00232728]\n",
      "  [0.0023741 ]\n",
      "  [0.00256369]\n",
      "  [0.00256679]\n",
      "  [0.00275756]\n",
      "  [0.00250072]\n",
      "  [0.00248865]\n",
      "  [0.00251475]\n",
      "  [0.00241427]\n",
      "  [0.00252382]\n",
      "  [0.00250272]]]\n"
     ]
    }
   ],
   "source": [
    " # Reshape the features data\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Print some sample data after reshaping the datasets\n",
    "print (f\"X_train sample values:\\n{X_train[:3]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Importing required Keras modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model.\n",
    "model = Sequential()\n",
    "\n",
    "# Initial model setup\n",
    "number_units = 100\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_22 (LSTM)               (None, 100, 100)          40800     \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 100, 100)          80400     \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 100, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_24 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 201,701\n",
      "Trainable params: 201,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Show the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 4s 35ms/step - loss: 1.7492e-04\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 5.1241e-05\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.4904e-05\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 9.3159e-06\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 3.9433e-06\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 3.7696e-06\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.4758e-06\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.4360e-06\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 8.7926e-07\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 8.2195e-07\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 8.6545e-07\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 6.5224e-07\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 6.9440e-07\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 6.2606e-07\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 7.7916e-07\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 7.2765e-07\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 6.6164e-07\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 6.7769e-07\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 6.9807e-07\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 8.2249e-07\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 7.4611e-07\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 7.7905e-07\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 7.6685e-07\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 8.5734e-07\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 7.9255e-07\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 7.2414e-07\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 8.5704e-07\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 7.0525e-07\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 9.1274e-07\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 7.5776e-07\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 8.0688e-07\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 8.5609e-07\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 8.2176e-07\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 7.6525e-07\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 7.9666e-07\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 9.5167e-07\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 8.6887e-07\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 9.1059e-07\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 8.0749e-07\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 8.6140e-07\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 8.6960e-07\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 9.4877e-07\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 9.5372e-07\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 8.7747e-07\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 9.5479e-07\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.0291e-06\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 8.9713e-07\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 9.5558e-07\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.0467e-06\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.0299e-06\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.0027e-06\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.0023e-06\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.0007e-06\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 9.9366e-07\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 9.8407e-07\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 9.4473e-07\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.1610e-06\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.2837e-06\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 9.6712e-07\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.0305e-06\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.1675e-06\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.0227e-06\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 8.8885e-07\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.0445e-06\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.1432e-06\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.0222e-06\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 9.7537e-07\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.2324e-06\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.2863e-06\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.1199e-06\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.1184e-06\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.3054e-06\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.1853e-06\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.1263e-06\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 1.0874e-06\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.1352e-06\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.0695e-06\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 1.1435e-06\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 9.8831e-07\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.1553e-06\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.3732e-06\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.0818e-06\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.2814e-06\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.3264e-06\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.1982e-06\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 9.8888e-07\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 1.4927e-06\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.2723e-06\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.1151e-06\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.2683e-06\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.3427e-06\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.3072e-06\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.3595e-06\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.3021e-06\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.4398e-06\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.2149e-06\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.2428e-06\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.1494e-06\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 1.3620e-06\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.2000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x17fecc41310>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, shuffle=False, batch_size=90, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Make predictions using the testing data X_test\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(235, 1)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-05</th>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.002681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-06</th>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.002680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-07</th>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.002680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-08</th>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.002680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-09</th>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.002679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Actual  Predicted\n",
       "Date                           \n",
       "2020-12-05  0.003401   0.002681\n",
       "2020-12-06  0.003386   0.002680\n",
       "2020-12-07  0.003320   0.002680\n",
       "2020-12-08  0.003216   0.002680\n",
       "2020-12-09  0.003213   0.002679"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Create a DataFrame of Real and Predicted values\n",
    "doge_eval = pd.DataFrame({\n",
    "    \"Actual\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = doge_df.index[-len(real_prices): ]) \n",
    "\n",
    "# Show the DataFrame's head\n",
    "doge_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Actual Vs. Predicted ETH Prices'}, xlabel='Date'>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Plot the real vs predicted prices as a line chart\n",
    "doge_eval.plot(title=\"Actual Vs. Predicted ETH Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04528726206144079\n",
      "0.2128080404059978\n",
      "0.14889060520157169\n"
     ]
    }
   ],
   "source": [
    "#seprate actual and pred\n",
    "Pred= doge_eval['Actual']\n",
    "act= doge_eval['Predicted']\n",
    "\n",
    "#model eval\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import math\n",
    "print(mean_squared_error(act, Pred))\n",
    "print(math.sqrt(mean_squared_error(act, Pred)))\n",
    "print(mean_absolute_error(act, Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create buy and sell signals \n",
    "#calculate profit and loss\n",
    "\n",
    "#create 'profit/loss' column to track trade metrics\n",
    "doge_eval['profit/loss'] = np.nan\n",
    "\n",
    "#create column to hold buy and cell signals\n",
    "doge_eval['signals'] = np.nan\n",
    "\n",
    "#create buy and sell list containers\n",
    "buy = []\n",
    "sell = []\n",
    "\n",
    "#create column that has next days price\n",
    "doge_eval['next_day'] = doge_eval[\"Predicted\"].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create loop that buys if next day price is higer and sells if next day price goes down\n",
    "for index, row in doge_eval.iterrows():\n",
    "\n",
    "    if row[\"Predicted\"] > row[\"next_day\"]:\n",
    "        doge_eval.loc[index, \"signals\"] = \"buy\"\n",
    "        buy.append(row[\"Actual\"])\n",
    "        doge_eval.loc[index, \"profit/loss\"] = 0\n",
    "    elif row[\"Predicted\"] < row[\"next_day\"]:\n",
    "        doge_eval.loc[index, \"signals\"] = \"sell\"\n",
    "        sell.append(row[\"Actual\"])\n",
    "        #doge_eval.loc[index, \"profit/loss\"] = sell[-1] - buy[-1]\n",
    "    else:\n",
    "        doge_eval.loc[index, \"signals\"] = \"hold\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create loop that buys if next day price is higer and sells if next day price goes down\n",
    "for index, row in doge_eval.iterrows():\n",
    "\n",
    "    if row[\"Predicted\"] > row[\"next_day\"]:\n",
    "        doge_eval.loc[index, \"signals\"] = \"buy\"\n",
    "        buy.append(row[\"Actual\"])\n",
    "        doge_eval.loc[index, \"profit/loss\"] = 0\n",
    "    elif row[\"Predicted\"] < row[\"next_day\"]:\n",
    "        doge_eval.loc[index, \"signals\"] = \"sell\"\n",
    "        sell.append(row[\"Actual\"])\n",
    "        doge_eval.loc[index, \"profit/loss\"] = sell[-1] - buy[-1]\n",
    "    else:\n",
    "        doge_eval.loc[index, \"signals\"] = \"hold\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "doge_eval.dropna(inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>profit/loss</th>\n",
       "      <th>signals</th>\n",
       "      <th>next_day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-12-05</th>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>buy</td>\n",
       "      <td>0.002680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-06</th>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>buy</td>\n",
       "      <td>0.002680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-07</th>\n",
       "      <td>0.003320</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>buy</td>\n",
       "      <td>0.002680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-08</th>\n",
       "      <td>0.003216</td>\n",
       "      <td>0.002680</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>buy</td>\n",
       "      <td>0.002679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-09</th>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>buy</td>\n",
       "      <td>0.002678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-22</th>\n",
       "      <td>0.190272</td>\n",
       "      <td>0.014612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>buy</td>\n",
       "      <td>0.014448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-23</th>\n",
       "      <td>0.192075</td>\n",
       "      <td>0.014448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>buy</td>\n",
       "      <td>0.014343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-24</th>\n",
       "      <td>0.195292</td>\n",
       "      <td>0.014343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>buy</td>\n",
       "      <td>0.014294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-25</th>\n",
       "      <td>0.195327</td>\n",
       "      <td>0.014294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>buy</td>\n",
       "      <td>0.014289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-26</th>\n",
       "      <td>0.204602</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>sell</td>\n",
       "      <td>0.014332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Actual  Predicted  profit/loss signals  next_day\n",
       "Date                                                          \n",
       "2020-12-05  0.003401   0.002681     0.000000     buy  0.002680\n",
       "2020-12-06  0.003386   0.002680     0.000000     buy  0.002680\n",
       "2020-12-07  0.003320   0.002680     0.000000     buy  0.002680\n",
       "2020-12-08  0.003216   0.002680     0.000000     buy  0.002679\n",
       "2020-12-09  0.003213   0.002679     0.000000     buy  0.002678\n",
       "...              ...        ...          ...     ...       ...\n",
       "2021-07-22  0.190272   0.014612     0.000000     buy  0.014448\n",
       "2021-07-23  0.192075   0.014448     0.000000     buy  0.014343\n",
       "2021-07-24  0.195292   0.014343     0.000000     buy  0.014294\n",
       "2021-07-25  0.195327   0.014294     0.000000     buy  0.014289\n",
       "2021-07-26  0.204602   0.014289     0.009275    sell  0.014332\n",
       "\n",
       "[234 rows x 5 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doge_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total profit/loss of the trading model is $10747.85, with the total return on investment being 1.07%\n"
     ]
    }
   ],
   "source": [
    "# calculate total profit/loss and percent return for 1000 total coins\n",
    "\n",
    "# total amount of initial capital\n",
    "initial_capital = 1000000\n",
    "\n",
    "# set total amount of coins\n",
    "coin_order = 1000\n",
    "\n",
    "# calculate total profit/loss\n",
    "total_profit_loss = round(doge_eval[\"profit/loss\"].sum() * coin_order, 2)\n",
    "\n",
    "# calculate return on investemnt \n",
    "roi = round((total_profit_loss / initial_capital) * 100, 2)\n",
    "\n",
    "# display profit/loss and roi\n",
    "print(\n",
    "    f\"The total profit/loss of the trading model is ${total_profit_loss}, \"\n",
    "    f\"with the total return on investment being {roi}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
